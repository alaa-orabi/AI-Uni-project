{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alaa-orabi/AI-Uni-project/blob/main/AppGui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiEIoOG8IRgw",
        "outputId": "3b93abee-24b2-4777-f741-88f446f1b142"
      },
      "id": "OiEIoOG8IRgw",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.52.2)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.4)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2.13.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.30.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2025-12-18T15:20:00.613146Z",
          "start_time": "2025-12-18T15:20:00.606189Z"
        },
        "id": "initial_id"
      },
      "source": [
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import cv2\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from PIL import ImageEnhance\n",
        "import os\n",
        "from io import StringIO\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from io import BytesIO\n",
        "import time\n",
        "from datetime import datetime\n",
        "import os\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import tensorflow as tf\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "from absl import logging\n",
        "logging.set_verbosity(logging.ERROR)"
      ],
      "outputs": [],
      "execution_count": 33
    },
    {
      "metadata": {
        "id": "8952b88f5b6d7218"
      },
      "cell_type": "markdown",
      "source": [
        "# Configuration"
      ],
      "id": "8952b88f5b6d7218"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-18T15:20:00.638273Z",
          "start_time": "2025-12-18T15:20:00.628485Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "75db11bcfd3bb8c6",
        "outputId": "5fb8499d-e066-409d-e6bd-45038be9fe82"
      },
      "cell_type": "code",
      "source": [
        "icon = Image.open(\"C:\\\\Users\\\\DCS\\\\Downloads\\\\Cream & Copper Leaf House Logo .png\")\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title=\"Plant Disease Detector\",\n",
        "    page_icon=icon,\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\",\n",
        "    menu_items={\n",
        "        'About': \"\"\"\n",
        "        # Plant Disease Detection System\n",
        "\n",
        "        **Version:** 1.0\n",
        "        **Framework:** TensorFlow + Streamlit\n",
        "        **Models:** ResNet50, EfficientNet, MobileNet\n",
        "\n",
        "        ---\n",
        "\n",
        "        **Team Members:**\n",
        "        - Mariam Mohamed\n",
        "        - Marina Shenouda\n",
        "        - Alaa Orabe\n",
        "        - Maria Gerges\n",
        "        - Ahmed Ayman\n",
        "\n",
        "        **Course:** AI Skills\n",
        "        **Date:** December 2025\n",
        "\n",
        "        Built with ❤️ for better agriculture\n",
        "        \"\"\"\n",
        "    }\n",
        ")"
      ],
      "id": "75db11bcfd3bb8c6",
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\DCS\\\\Downloads\\\\Cream & Copper Leaf House Logo .png'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3768861929.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0micon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"C:\\\\Users\\\\DCS\\\\Downloads\\\\Cream & Copper Leaf House Logo .png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m st.set_page_config(\n\u001b[1;32m      4\u001b[0m     \u001b[0mpage_title\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Plant Disease Detector\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpage_icon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0micon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3512\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3513\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3514\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3515\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\DCS\\\\Downloads\\\\Cream & Copper Leaf House Logo .png'"
          ]
        }
      ],
      "execution_count": 34
    },
    {
      "metadata": {
        "id": "f8b7f8c9717bdb27"
      },
      "cell_type": "markdown",
      "source": [
        "# Styling"
      ],
      "id": "f8b7f8c9717bdb27"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-18T15:20:00.700578Z",
          "start_time": "2025-12-18T15:20:00.682495Z"
        },
        "id": "a8045ca4bb375d59"
      },
      "cell_type": "code",
      "source": [
        "def load_custom_css():\n",
        "    st.markdown(\"\"\"\n",
        "    <style>\n",
        "        @import url('https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500;600;700;800&display=swap');\n",
        "\n",
        "        * {\n",
        "            font-family: 'Poppins', sans-serif;\n",
        "        }\n",
        "\n",
        "        html, body, [class*=\"css\"] {\n",
        "            font-family: 'Poppins', sans-serif;\n",
        "        }\n",
        "\n",
        "        .stApp {\n",
        "            background: linear-gradient(135deg, #e8f5e9 0%, #a5d6a7 50%, #81c784 100%);\n",
        "            background-attachment: fixed;\n",
        "        }\n",
        "\n",
        "        .stApp::before {\n",
        "            content: \"\";\n",
        "            position: fixed;\n",
        "            top: 0;\n",
        "            left: 0;\n",
        "            width: 100%;\n",
        "            height: 100%;\n",
        "            background:\n",
        "                radial-gradient(circle at 20% 50%, rgba(102, 187, 106, 0.1) 0%, transparent 50%),\n",
        "                radial-gradient(circle at 80% 80%, rgba(46, 125, 50, 0.1) 0%, transparent 50%);\n",
        "            z-index: 0;\n",
        "            pointer-events: none;\n",
        "        }\n",
        "\n",
        "        section[data-testid=\"stSidebar\"] {\n",
        "            background: linear-gradient(180deg, #1b5e20 0%, #2e7d32 50%, #388e3c 100%);\n",
        "            box-shadow: 4px 0 20px rgba(0,0,0,0.1);\n",
        "        }\n",
        "\n",
        "        section[data-testid=\"stSidebar\"] * {\n",
        "            color: white !important;\n",
        "        }\n",
        "\n",
        "        section[data-testid=\"stSidebar\"] .stMarkdown {\n",
        "            color: white !important;\n",
        "        }\n",
        "\n",
        "        /* Sidebar headers glow effect */\n",
        "        section[data-testid=\"stSidebar\"] h1,\n",
        "        section[data-testid=\"stSidebar\"] h2,\n",
        "        section[data-testid=\"stSidebar\"] h3 {\n",
        "            color: white !important;\n",
        "            text-shadow: 0 0 10px rgba(255,255,255,0.3);\n",
        "        }\n",
        "\n",
        "        h1 {\n",
        "            color: #1b5e20 !important;\n",
        "            font-weight: 700 !important;\n",
        "            text-shadow: 2px 2px 4px rgba(0,0,0,0.1);\n",
        "        }\n",
        "\n",
        "        h2 {\n",
        "            color: #2e7d32 !important;\n",
        "            font-weight: 600 !important;\n",
        "        }\n",
        "\n",
        "        h3 {\n",
        "            color: #388e3c !important;\n",
        "            font-weight: 500 !important;\n",
        "        }\n",
        "\n",
        "        .stButton>button {\n",
        "            background: linear-gradient(135deg, #2e7d32 0%, #43a047 50%, #66bb6a 100%);\n",
        "            color: white;\n",
        "            border: none;\n",
        "            border-radius: 12px;\n",
        "            padding: 0.6rem 2.5rem;\n",
        "            font-weight: 600;\n",
        "            font-size: 1rem;\n",
        "            transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);\n",
        "            box-shadow: 0 4px 15px rgba(67, 160, 71, 0.4);\n",
        "            position: relative;\n",
        "            overflow: hidden;\n",
        "        }\n",
        "\n",
        "        .stButton>button:hover {\n",
        "            transform: translateY(-3px) scale(1.02);\n",
        "            box-shadow: 0 8px 25px rgba(67, 160, 71, 0.5);\n",
        "            background: linear-gradient(135deg, #1b5e20 0%, #2e7d32 50%, #43a047 100%);\n",
        "        }\n",
        "\n",
        "        .stButton>button:active {\n",
        "            transform: translateY(-1px);\n",
        "        }\n",
        "\n",
        "        /* Button shine effect */\n",
        "        .stButton>button::before {\n",
        "            content: '';\n",
        "            position: absolute;\n",
        "            top: 0;\n",
        "            left: -100%;\n",
        "            width: 100%;\n",
        "            height: 100%;\n",
        "            background: linear-gradient(90deg, transparent, rgba(255,255,255,0.3), transparent);\n",
        "            transition: left 0.5s;\n",
        "        }\n",
        "\n",
        "        .stButton>button:hover::before {\n",
        "            left: 100%;\n",
        "        }\n",
        "\n",
        "        .stTabs [data-baseweb=\"tab-list\"] {\n",
        "            gap: 10px;\n",
        "            background: rgba(255, 255, 255, 0.9);\n",
        "            border-radius: 15px;\n",
        "            padding: 0.8rem;\n",
        "            box-shadow: 0 4px 15px rgba(0,0,0,0.1);\n",
        "        }\n",
        "\n",
        "        .stTabs [data-baseweb=\"tab\"] {\n",
        "            border-radius: 10px;\n",
        "            padding: 0.6rem 1.5rem;\n",
        "            background-color: transparent;\n",
        "            color: #2e7d32;\n",
        "            font-weight: 500;\n",
        "            transition: all 0.3s ease;\n",
        "        }\n",
        "\n",
        "        .stTabs [data-baseweb=\"tab\"]:hover {\n",
        "            background-color: rgba(102, 187, 106, 0.1);\n",
        "            transform: translateY(-2px);\n",
        "        }\n",
        "\n",
        "        .stTabs [aria-selected=\"true\"] {\n",
        "            background: linear-gradient(135deg, #43a047 0%, #66bb6a 100%) !important;\n",
        "            color: white !important;\n",
        "            box-shadow: 0 4px 12px rgba(67, 160, 71, 0.4);\n",
        "            font-weight: 600;\n",
        "        }\n",
        "\n",
        "        [data-testid=\"stMetricValue\"] {\n",
        "            font-size: 2.5rem;\n",
        "            font-weight: 700;\n",
        "            color: #2e7d32;\n",
        "            text-shadow: 1px 1px 2px rgba(0,0,0,0.1);\n",
        "        }\n",
        "\n",
        "        [data-testid=\"stMetricDelta\"] {\n",
        "            font-size: 1rem;\n",
        "        }\n",
        "\n",
        "        [data-testid=\"metric-container\"] {\n",
        "            background: rgba(255, 255, 255, 0.8);\n",
        "            border-radius: 12px;\n",
        "            padding: 1rem;\n",
        "            box-shadow: 0 4px 12px rgba(0,0,0,0.08);\n",
        "            transition: transform 0.3s ease;\n",
        "        }\n",
        "\n",
        "        [data-testid=\"metric-container\"]:hover {\n",
        "            transform: translateY(-3px);\n",
        "            box-shadow: 0 6px 20px rgba(0,0,0,0.12);\n",
        "        }\n",
        "\n",
        "        [data-testid=\"stFileUploader\"] {\n",
        "            background: rgba(255, 255, 255, 0.95);\n",
        "            border-radius: 20px;\n",
        "            padding: 2.5rem;\n",
        "            border: 3px dashed #66bb6a;\n",
        "            transition: all 0.3s ease;\n",
        "        }\n",
        "\n",
        "        [data-testid=\"stFileUploader\"]:hover {\n",
        "            border-color: #43a047;\n",
        "            background: rgba(255, 255, 255, 1);\n",
        "            box-shadow: 0 8px 30px rgba(102, 187, 106, 0.2);\n",
        "            transform: scale(1.01);\n",
        "        }\n",
        "\n",
        "        .stProgress > div > div > div > div {\n",
        "            background: linear-gradient(90deg, #2e7d32 0%, #43a047 50%, #66bb6a 100%);\n",
        "            border-radius: 10px;\n",
        "        }\n",
        "\n",
        "        .stProgress > div > div {\n",
        "            background-color: rgba(224, 224, 224, 0.5);\n",
        "            border-radius: 10px;\n",
        "        }\n",
        "\n",
        "        .prediction-card {\n",
        "            background: rgba(255, 255, 255, 0.95);\n",
        "            padding: 2.5rem;\n",
        "            border-radius: 20px;\n",
        "            box-shadow: 0 8px 30px rgba(0,0,0,0.12);\n",
        "            transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);\n",
        "            border-left: 6px solid #43a047;\n",
        "        }\n",
        "\n",
        "        /* Info boxes */\n",
        "        .info-box {\n",
        "            background: linear-gradient(135deg, #fff9c4 0%, #fff59d 100%);\n",
        "            padding: 1.5rem;\n",
        "            border-radius: 12px;\n",
        "            border-left: 5px solid #fbc02d;\n",
        "            margin: 1rem 0;\n",
        "            box-shadow: 0 4px 12px rgba(251, 192, 45, 0.2);\n",
        "        }\n",
        "\n",
        "        .success-box {\n",
        "            background: linear-gradient(135deg, #e8f5e9 0%, #c8e6c9 100%);\n",
        "            padding: 1.5rem;\n",
        "            border-radius: 12px;\n",
        "            border-left: 5px solid #4caf50;\n",
        "            margin: 1rem 0;\n",
        "            box-shadow: 0 4px 12px rgba(76, 175, 80, 0.2);\n",
        "        }\n",
        "\n",
        "        .warning-box {\n",
        "            background: linear-gradient(135deg, #fff3e0 0%, #ffe0b2 100%);\n",
        "            padding: 1.5rem;\n",
        "            border-radius: 12px;\n",
        "            border-left: 5px solid #ff9800;\n",
        "            margin: 1rem 0;\n",
        "            box-shadow: 0 4px 12px rgba(255, 152, 0, 0.2);\n",
        "        }\n",
        "\n",
        "        .streamlit-expanderHeader {\n",
        "            background: rgba(255, 255, 255, 0.15);\n",
        "            border-radius: 10px;\n",
        "            padding: 0.8rem;\n",
        "            transition: all 0.3s ease;\n",
        "        }\n",
        "\n",
        "        .streamlit-expanderHeader:hover {\n",
        "            background: rgba(255, 255, 255, 0.25);\n",
        "        }\n",
        "\n",
        "        [data-testid=\"stCamera\"] {\n",
        "            border-radius: 20px;\n",
        "            overflow: hidden;\n",
        "            box-shadow: 0 8px 30px rgba(0,0,0,0.25);\n",
        "            border: 3px solid #66bb6a;\n",
        "        }\n",
        "\n",
        "        .stImage {\n",
        "            border-radius: 15px;\n",
        "            overflow: hidden;\n",
        "            box-shadow: 0 4px 15px rgba(0,0,0,0.1);\n",
        "        }\n",
        "\n",
        "        [data-testid=\"stDataFrame\"] {\n",
        "            border-radius: 15px;\n",
        "            overflow: hidden;\n",
        "            box-shadow: 0 4px 20px rgba(0,0,0,0.1);\n",
        "        }\n",
        "\n",
        "        .stSelectbox > div > div {\n",
        "            border-radius: 10px;\n",
        "            border-color: #66bb6a;\n",
        "        }\n",
        "\n",
        "        .stRadio > div {\n",
        "            background: rgba(255, 255, 255, 0.5);\n",
        "            padding: 0.5rem;\n",
        "            border-radius: 10px;\n",
        "        }\n",
        "\n",
        "        ::-webkit-scrollbar {\n",
        "            width: 10px;\n",
        "            height: 10px;\n",
        "        }\n",
        "\n",
        "        ::-webkit-scrollbar-track {\n",
        "            background: rgba(200, 230, 201, 0.3);\n",
        "            border-radius: 10px;\n",
        "        }\n",
        "\n",
        "        ::-webkit-scrollbar-thumb {\n",
        "            background: linear-gradient(180deg, #43a047, #66bb6a);\n",
        "            border-radius: 10px;\n",
        "        }\n",
        "\n",
        "        ::-webkit-scrollbar-thumb:hover {\n",
        "            background: linear-gradient(180deg, #2e7d32, #43a047);\n",
        "        }\n",
        "\n",
        "        @keyframes fadeIn {\n",
        "            from { opacity: 0; transform: translateY(20px); }\n",
        "            to { opacity: 1; transform: translateY(0); }\n",
        "        }\n",
        "\n",
        "        .stMarkdown, .stImage, .prediction-card {\n",
        "            animation: fadeIn 0.6s ease-out;\n",
        "        }\n",
        "\n",
        "    </style>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "load_custom_css()"
      ],
      "id": "a8045ca4bb375d59",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "97c9640689b81ba9"
      },
      "cell_type": "markdown",
      "source": [
        "# Paths"
      ],
      "id": "97c9640689b81ba9"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-18T15:20:00.766011Z",
          "start_time": "2025-12-18T15:20:00.761044Z"
        },
        "id": "7ed1eed19df4fd09"
      },
      "cell_type": "code",
      "source": [
        "MODEL_PATH = \"C:\\\\Users\\\\DCS\\\\Desktop\\\\PlantDiseaseProject\\\\models\\\\resnet50_model.h5\"\n",
        "EFFICIENTNET_PATH = \"C:\\\\Users\\\\DCS\\\\Desktop\\\\PlantDiseaseProject\\\\models\\\\efficientnet_model.h5\"\n",
        "MOBILENET_PATH = \"C:\\\\Users\\\\DCS\\\\Desktop\\\\PlantDiseaseProject\\\\models\\\\mobilenet_model.h5\"\n",
        "CLASS_NAMES_PATH =\"C:\\\\Users\\\\DCS\\\\Desktop\\\\PlantDiseaseProject\\\\models\\\\class_names.json\"\n",
        "\n",
        "IMG_SIZE = (224, 224)\n"
      ],
      "id": "7ed1eed19df4fd09",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "2896b1274d5d433a"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Model and Classes"
      ],
      "id": "2896b1274d5d433a"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-18T15:20:00.799686Z",
          "start_time": "2025-12-18T15:20:00.776526Z"
        },
        "id": "dcf5a55b20973c5e"
      },
      "cell_type": "code",
      "source": [
        "@st.cache_resource\n",
        "def load_model(model_name):\n",
        "    models = {\n",
        "        'ResNet50': (MODEL_PATH, tf.keras.applications.resnet50.preprocess_input),\n",
        "        'EfficientNetB3': (EFFICIENTNET_PATH, tf.keras.applications.efficientnet.preprocess_input),\n",
        "        'MobileNet': (MOBILENET_PATH, tf.keras.applications.mobilenet_v2.preprocess_input)\n",
        "    }\n",
        "\n",
        "    if model_name not in models:\n",
        "        return None, None, None\n",
        "\n",
        "    model_path, preprocess_fn = models[model_name]\n",
        "\n",
        "    try:\n",
        "        if not Path(model_path).exists():\n",
        "            st.error(f\"{model_name} not found at {model_path}\")\n",
        "            return None, None, None\n",
        "\n",
        "        model = tf.keras.models.load_model(str(model_path))\n",
        "\n",
        "        class_data = None\n",
        "        if Path(CLASS_NAMES_PATH).exists():\n",
        "            with open(CLASS_NAMES_PATH, 'r', encoding='utf-8') as f:\n",
        "                class_data = json.load(f)\n",
        "\n",
        "        return model, preprocess_fn, class_data\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading {model_name}: {str(e)}\")\n",
        "        return None, None, None\n",
        "\n",
        "\n",
        "def get_available_models():\n",
        "    models = {\n",
        "        'ResNet50': {'path': MODEL_PATH, 'accuracy': '94.5%', 'speed': 'Fast'},\n",
        "        'EfficientNetB3': {'path': EFFICIENTNET_PATH, 'accuracy': '96.2%', 'speed': 'Medium'},\n",
        "        'MobileNet': {'path': MOBILENET_PATH, 'accuracy': '91.8%', 'speed': 'Very Fast'}\n",
        "    }\n",
        "\n",
        "    available = {}\n",
        "    for name, info in models.items():\n",
        "        path = Path(info['path'])\n",
        "        if path.exists():\n",
        "            available[name] = {\n",
        "                **info,\n",
        "                'size': f\"{path.stat().st_size / (1024**2):.1f} MB\"\n",
        "            }\n",
        "\n",
        "    return available\n",
        "\n",
        "\n",
        "def display_model_status():\n",
        "    available = get_available_models()\n",
        "\n",
        "    if not available:\n",
        "        st.error(\"No models found! Place models in models/ directory\")\n",
        "        st.stop()\n",
        "\n",
        "    st.sidebar.success(f\"{len(available)} model(s) available\")\n",
        "\n",
        "    for name, info in available.items():\n",
        "        with st.sidebar.expander(f\"{name}\"):\n",
        "            st.write(f\"Accuracy: {info['accuracy']}\")\n",
        "            st.write(f\"Speed: {info['speed']}\")\n",
        "            st.write(f\"Size: {info['size']}\")\n",
        "\n",
        "\n",
        "def initialize_app():\n",
        "    available = get_available_models()\n",
        "    models_dict = {}\n",
        "    class_data = None\n",
        "\n",
        "    if Path(CLASS_NAMES_PATH).exists():\n",
        "        with open(CLASS_NAMES_PATH, 'r', encoding='utf-8') as f:\n",
        "            class_data = json.load(f)\n",
        "\n",
        "    for name in available:\n",
        "        model, preprocess, _ = load_model(name)\n",
        "        if model:\n",
        "            models_dict[name] = {'model': model, 'preprocess': preprocess, 'loaded': True}\n",
        "\n",
        "    return models_dict, class_data, list(models_dict.keys())"
      ],
      "id": "dcf5a55b20973c5e",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "9d94d0f3e838198e"
      },
      "cell_type": "markdown",
      "source": [
        "# Grad-CAM Implementation"
      ],
      "id": "9d94d0f3e838198e"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-18T15:20:00.835823Z",
          "start_time": "2025-12-18T15:20:00.808749Z"
        },
        "id": "3e85f511bcd52df8"
      },
      "cell_type": "code",
      "source": [
        "def find_last_conv_layer(model):\n",
        "    for layer in reversed(model.layers):\n",
        "        if 'conv' in layer.name.lower() and 'bn' not in layer.name.lower():\n",
        "            return layer.name\n",
        "    for layer in reversed(model.layers):\n",
        "        if 'activation' in layer.name.lower() or 'relu' in layer.name.lower():\n",
        "            return layer.name\n",
        "    return None\n",
        "\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name=None, pred_index=None):\n",
        "    try:\n",
        "        if last_conv_layer_name is None:\n",
        "            last_conv_layer_name = find_last_conv_layer(model)\n",
        "\n",
        "        if last_conv_layer_name is None:\n",
        "            st.warning(\"Could not find convolutional layer for Grad-CAM\")\n",
        "            return None\n",
        "\n",
        "        grad_model = tf.keras.models.Model(\n",
        "            inputs=[model.inputs],\n",
        "            outputs=[model.get_layer(last_conv_layer_name).output, model.output]\n",
        "        )\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            conv_outputs, predictions = grad_model(img_array)\n",
        "            if pred_index is None:\n",
        "                pred_index = tf.argmax(predictions[0])\n",
        "\n",
        "            class_channel = predictions[:, pred_index]\n",
        "\n",
        "        grads = tape.gradient(class_channel, conv_outputs)\n",
        "\n",
        "        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "        conv_outputs = conv_outputs[0]\n",
        "        heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "        heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "        heatmap = tf.maximum(heatmap, 0) / (tf.math.reduce_max(heatmap) + 1e-10)\n",
        "\n",
        "        return heatmap.numpy()\n",
        "\n",
        "    except Exception as e:\n",
        "        st.warning(f\"Grad-CAM generation failed: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def create_gradcam_overlay(img, heatmap, alpha=0.4, colormap=cv2.COLORMAP_JET):\n",
        "    try:\n",
        "        heatmap_resized = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "        heatmap_uint8 = np.uint8(255 * heatmap_resized)\n",
        "        heatmap_colored = cv2.applyColorMap(heatmap_uint8, colormap)\n",
        "        heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if img.dtype != np.uint8:\n",
        "            img = np.uint8(img)\n",
        "\n",
        "        superimposed = heatmap_colored * alpha + img * (1 - alpha)\n",
        "        return np.clip(superimposed, 0, 255).astype(np.uint8)\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error creating overlay: {str(e)}\")\n",
        "        return img\n",
        "\n",
        "\n",
        "def create_gradcam_visualization(img, heatmap, alpha=0.4):\n",
        "    try:\n",
        "        heatmap_resized = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "        heatmap_uint8 = np.uint8(255 * heatmap_resized)\n",
        "        heatmap_colored = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)\n",
        "        heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)\n",
        "        overlay = create_gradcam_overlay(img, heatmap, alpha)\n",
        "        return img, heatmap_colored, overlay\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Visualization error: {str(e)}\")\n",
        "        return img, img, img\n",
        "\n",
        "\n",
        "def compare_gradcams(img, models_dict, class_idx=None):\n",
        "    gradcams = {}\n",
        "\n",
        "    for model_name, model_info in models_dict.items():\n",
        "        if not model_info.get('loaded', False):\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            img_resized = img.resize(IMG_SIZE)\n",
        "            img_array = tf.keras.preprocessing.image.img_to_array(img_resized)\n",
        "            img_array = model_info['preprocess'](img_array)\n",
        "            img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "            model = model_info['model']\n",
        "            heatmap = make_gradcam_heatmap(img_array, model, pred_index=class_idx)\n",
        "\n",
        "            if heatmap is not None:\n",
        "                gradcams[model_name] = heatmap\n",
        "\n",
        "        except Exception as e:\n",
        "            st.warning(f\"Grad-CAM failed for {model_name}: {str(e)}\")\n",
        "\n",
        "    return gradcams\n",
        "\n",
        "\n",
        "def display_gradcam_analysis(img, heatmap, prediction, confidence):\n",
        "    st.markdown(\"### Grad-CAM Analysis - Explainable AI\")\n",
        "\n",
        "    if heatmap is None:\n",
        "        st.warning(\"Grad-CAM not available for this model/image\")\n",
        "        return\n",
        "\n",
        "    if not isinstance(heatmap, np.ndarray):\n",
        "        st.error(\"Invalid heatmap data\")\n",
        "        return\n",
        "\n",
        "    img_array = np.array(img.resize(IMG_SIZE))\n",
        "    original, heatmap_colored, overlay = create_gradcam_visualization(img_array, heatmap)\n",
        "\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "\n",
        "    with col1:\n",
        "        st.markdown(\"**Original Image**\")\n",
        "        st.image(original, use_container_width=True)\n",
        "        st.caption(\"Input leaf image\")\n",
        "\n",
        "    with col2:\n",
        "        st.markdown(\"**Attention Heatmap**\")\n",
        "        st.image(heatmap_colored, use_container_width=True)\n",
        "        st.caption(\"AI focus areas\")\n",
        "\n",
        "    with col3:\n",
        "        st.markdown(\"**Combined View**\")\n",
        "        st.image(overlay, use_container_width=True)\n",
        "        st.caption(\"Overlay visualization\")\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    col_a, col_b = st.columns([2, 1])\n",
        "\n",
        "    with col_a:\n",
        "        st.markdown(\"#### How to Interpret Grad-CAM\")\n",
        "        st.markdown(\"\"\"\n",
        "        <div class=\"info-box\">\n",
        "        <p><b>Understanding the Heatmap:</b></p>\n",
        "        <ul>\n",
        "            <li><span style=\"color: #d32f2f;\">Red/Hot regions:</span>\n",
        "                Areas the model considers most important for the diagnosis.</li>\n",
        "            <li><span style=\"color: #fbc02d;\">Yellow/Warm regions:</span>\n",
        "                Moderately important areas that contribute to the prediction.</li>\n",
        "            <li><span style=\"color: #1976d2;\">Blue/Cool regions:</span>\n",
        "                Low relevance areas that do not significantly affect the decision.</li>\n",
        "        </ul>\n",
        "        <p><b>What the AI is looking at:</b></p>\n",
        "        <ul>\n",
        "            <li>Disease patterns and symptoms</li>\n",
        "            <li>Leaf texture and color abnormalities</li>\n",
        "            <li>Spots, lesions, or discoloration</li>\n",
        "            <li>Overall leaf structure and health</li>\n",
        "        </ul>\n",
        "        </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    with col_b:\n",
        "        st.markdown(\"#### Analysis Stats\")\n",
        "\n",
        "        try:\n",
        "            hot_spots = np.sum(heatmap > 0.7) / heatmap.size * 100\n",
        "            warm_areas = np.sum((heatmap > 0.4) & (heatmap <= 0.7)) / heatmap.size * 100\n",
        "\n",
        "            st.metric(\"Hot Spots\", f\"{hot_spots:.1f}%\")\n",
        "            st.metric(\"Warm Areas\", f\"{warm_areas:.1f}%\")\n",
        "            st.metric(\"Prediction\", f\"{confidence:.1f}%\")\n",
        "\n",
        "            if confidence > 90:\n",
        "                st.success(\"Very High Confidence\")\n",
        "            elif confidence > 75:\n",
        "                st.info(\"High Confidence\")\n",
        "            elif confidence > 60:\n",
        "                st.warning(\"Moderate Confidence\")\n",
        "            else:\n",
        "                st.error(\"Low Confidence - Review needed\")\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error calculating heatmap stats: {str(e)}\")\n",
        "\n",
        "\n",
        "def export_gradcam_visualization(img, heatmap, prediction, output_path=None):\n",
        "    try:\n",
        "        img_array = np.array(img.resize(IMG_SIZE))\n",
        "        original, heatmap_colored, overlay = create_gradcam_visualization(img_array, heatmap)\n",
        "        combined = np.hstack([original, heatmap_colored, overlay])\n",
        "        combined_pil = Image.fromarray(combined)\n",
        "\n",
        "        draw = ImageDraw.Draw(combined_pil)\n",
        "        try:\n",
        "            font = ImageFont.truetype(\"arial.ttf\", 20)\n",
        "        except:\n",
        "            font = ImageFont.load_default()\n",
        "\n",
        "        labels = [\"Original\", \"Heatmap\", \"Overlay\"]\n",
        "        for i, label in enumerate(labels):\n",
        "            draw.text((i * IMG_SIZE[0] + 10, 10), label, fill=(255, 255, 255), font=font)\n",
        "\n",
        "        if output_path:\n",
        "            combined_pil.save(output_path)\n",
        "\n",
        "        return combined_pil\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Export failed: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def predict_tflite(img_array, tflite_model_path):\n",
        "    try:\n",
        "        interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
        "        interpreter.allocate_tensors()\n",
        "        input_details = interpreter.get_input_details()\n",
        "        output_details = interpreter.get_output_details()\n",
        "\n",
        "        interpreter.set_tensor(input_details[0]['index'], img_array)\n",
        "        interpreter.invoke()\n",
        "        return interpreter.get_tensor(output_details[0]['index'])\n",
        "    except:\n",
        "        return None"
      ],
      "id": "3e85f511bcd52df8",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "56693247269a186f"
      },
      "cell_type": "markdown",
      "source": [
        "# BONUS: Image Enhancement & Preprocessing"
      ],
      "id": "56693247269a186f"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-18T15:20:00.875530Z",
          "start_time": "2025-12-18T15:20:00.845776Z"
        },
        "id": "46530122c783c50e"
      },
      "cell_type": "code",
      "source": [
        "def enhance_image(img, brightness=1.0, contrast=1.0, sharpness=1.0, color=1.0):\n",
        "    try:\n",
        "        enhanced = img.copy()\n",
        "\n",
        "        if brightness != 1.0:\n",
        "            enhanced = ImageEnhance.Brightness(enhanced).enhance(brightness)\n",
        "\n",
        "        if contrast != 1.0:\n",
        "            enhanced = ImageEnhance.Contrast(enhanced).enhance(contrast)\n",
        "\n",
        "        if sharpness != 1.0:\n",
        "            enhanced = ImageEnhance.Sharpness(enhanced).enhance(sharpness)\n",
        "\n",
        "        if color != 1.0:\n",
        "            enhanced = ImageEnhance.Color(enhanced).enhance(color)\n",
        "\n",
        "        return enhanced\n",
        "\n",
        "    except Exception as e:\n",
        "        st.warning(f\" Enhancement failed: {str(e)}\")\n",
        "        return img\n",
        "\n",
        "\n",
        "def enhance_clahe(img):\n",
        "\n",
        "    try:\n",
        "        img_array = np.array(img)\n",
        "        lab = cv2.cvtColor(img_array, cv2.COLOR_RGB2LAB)\n",
        "        l, a, b = cv2.split(lab)\n",
        "\n",
        "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
        "        l = clahe.apply(l)\n",
        "\n",
        "        enhanced = cv2.merge([l, a, b])\n",
        "        enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2RGB)\n",
        "\n",
        "        return Image.fromarray(enhanced)\n",
        "    except:\n",
        "        return img\n",
        "\n",
        "\n",
        "def show_enhancement_controls():\n",
        "    st.markdown(\"####  Enhance Image\")\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        brightness = st.slider(\" Brightness\", 0.5, 2.0, 1.0, 0.1)\n",
        "        sharpness = st.slider(\" Sharpness\", 0.5, 2.0, 1.0, 0.1)\n",
        "\n",
        "    with col2:\n",
        "        contrast = st.slider(\" Contrast\", 0.5, 2.0, 1.0, 0.1)\n",
        "        color = st.slider(\" Color\", 0.5, 2.0, 1.0, 0.1)\n",
        "\n",
        "    use_clahe = st.checkbox(\"✨ Auto-Enhance (CLAHE)\", value=False)\n",
        "\n",
        "    return {\n",
        "        'brightness': brightness,\n",
        "        'contrast': contrast,\n",
        "        'sharpness': sharpness,\n",
        "        'color': color,\n",
        "        'use_clahe': use_clahe\n",
        "    }\n",
        "\n",
        "\n",
        "def apply_enhancements(img, params):\n",
        "    enhanced = img.copy()\n",
        "\n",
        "    if params.get('use_clahe', False):\n",
        "        enhanced = enhance_clahe(enhanced)\n",
        "\n",
        "    enhanced = enhance_image(\n",
        "        enhanced,\n",
        "        brightness=params.get('brightness', 1.0),\n",
        "        contrast=params.get('contrast', 1.0),\n",
        "        sharpness=params.get('sharpness', 1.0),\n",
        "        color=params.get('color', 1.0)\n",
        "    )\n",
        "\n",
        "    return enhanced\n",
        "\n",
        "\n",
        "def show_before_after(original, enhanced):\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        st.markdown(\"**Original**\")\n",
        "        st.image(original, use_container_width=True)\n",
        "\n",
        "    with col2:\n",
        "        st.markdown(\"**Enhanced**\")\n",
        "        st.image(enhanced, use_container_width=True)"
      ],
      "id": "46530122c783c50e",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "65f5429c63493626"
      },
      "cell_type": "markdown",
      "source": [
        "# Prediction Function with Ensemble"
      ],
      "id": "65f5429c63493626"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-18T15:20:00.910280Z",
          "start_time": "2025-12-18T15:20:00.884943Z"
        },
        "id": "db5715f9a500c005"
      },
      "cell_type": "code",
      "source": [
        "def predict_disease(img, model, class_data, preprocess_fn=None, use_enhancement=False):\n",
        "\n",
        "    try:\n",
        "        if preprocess_fn is None:\n",
        "            preprocess_fn = tf.keras.applications.resnet50.preprocess_input\n",
        "\n",
        "        # Preprocess image\n",
        "        img_resized = img.resize(IMG_SIZE)\n",
        "        img_array = tf.keras.preprocessing.image.img_to_array(img_resized)\n",
        "        img_array = preprocess_fn(img_array)\n",
        "        img_array_batch = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "        predictions = model.predict(img_array_batch, verbose=0)\n",
        "\n",
        "        if use_enhancement:\n",
        "            try:\n",
        "                img_enhanced = enhance_clahe(img)\n",
        "                img_enh_resized = img_enhanced.resize(IMG_SIZE)\n",
        "                img_enh_array = tf.keras.preprocessing.image.img_to_array(img_enh_resized)\n",
        "                img_enh_array = preprocess_fn(img_enh_array)\n",
        "                img_enh_batch = np.expand_dims(img_enh_array, axis=0)\n",
        "\n",
        "                predictions_enh = model.predict(img_enh_batch, verbose=0)\n",
        "                predictions = (predictions + predictions_enh) / 2\n",
        "            except Exception as e:\n",
        "                st.warning(f\"⚠️ Enhancement ensemble failed: {str(e)}\")\n",
        "\n",
        "        # Get top 3 predictions\n",
        "        top3_idx = np.argsort(predictions[0])[-3:][::-1]\n",
        "\n",
        "        # FIXED: Handle different JSON structures\n",
        "        try:\n",
        "            # Try formatted_names first\n",
        "            if 'formatted_names' in class_data:\n",
        "                top3_classes = [class_data['formatted_names'][i] for i in top3_idx]\n",
        "            # Try indexed dict structure\n",
        "            elif str(top3_idx[0]) in class_data:\n",
        "                top3_classes = [class_data[str(i)]['name'] for i in top3_idx]\n",
        "            # Try direct list\n",
        "            elif isinstance(class_data, list):\n",
        "                top3_classes = [class_data[i] for i in top3_idx]\n",
        "            else:\n",
        "                # Fallback\n",
        "                top3_classes = [f\"Class_{i}\" for i in top3_idx]\n",
        "                st.warning(\"⚠️ Class names structure not recognized, using fallback\")\n",
        "        except (KeyError, IndexError) as e:\n",
        "            st.error(f\"❌ Error accessing class names: {str(e)}\")\n",
        "            top3_classes = [f\"Class_{i}\" for i in top3_idx]\n",
        "\n",
        "        top3_probs = [float(predictions[0][i]) * 100 for i in top3_idx]\n",
        "\n",
        "        # Generate Grad-CAM heatmap\n",
        "        heatmap = None\n",
        "        try:\n",
        "            heatmap = make_gradcam_heatmap(img_array_batch, model, pred_index=int(top3_idx[0]))\n",
        "        except Exception as e:\n",
        "            st.warning(f\"⚠️ Grad-CAM generation failed: {str(e)}\")\n",
        "\n",
        "        return top3_classes, top3_probs, heatmap, predictions[0]\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"❌ Prediction failed: {str(e)}\")\n",
        "        import traceback\n",
        "        st.error(f\"Details: {traceback.format_exc()}\")\n",
        "        return None, None, None, None\n",
        "\n",
        "\n",
        "def predict_with_model(img, model_name, models_dict, class_data, use_enhancement=False):\n",
        "    \"\"\"\n",
        "    Predict disease using a specific model\n",
        "\n",
        "    Args:\n",
        "        img: PIL Image\n",
        "        model_name: Name of model to use\n",
        "        models_dict: Dictionary of loaded models\n",
        "        class_data: Class information\n",
        "        use_enhancement: Use enhancement ensemble\n",
        "\n",
        "    Returns:\n",
        "        dict: Prediction results including timing and confidence\n",
        "    \"\"\"\n",
        "    if model_name not in models_dict or not models_dict[model_name].get('loaded', False):\n",
        "        st.error(f\"❌ Model {model_name} not available\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        model = models_dict[model_name]['model']\n",
        "        preprocess_fn = models_dict[model_name]['preprocess']\n",
        "\n",
        "        # Measure inference time\n",
        "        start_time = time.time()\n",
        "\n",
        "        top3_classes, top3_probs, heatmap, all_preds = predict_disease(\n",
        "            img, model, class_data, preprocess_fn, use_enhancement\n",
        "        )\n",
        "\n",
        "        inference_time = time.time() - start_time\n",
        "\n",
        "        if top3_classes is None:\n",
        "            return None\n",
        "\n",
        "        return {\n",
        "            'model_name': model_name,\n",
        "            'top3_classes': top3_classes,\n",
        "            'top3_probs': top3_probs,\n",
        "            'heatmap': heatmap,\n",
        "            'all_predictions': all_preds,\n",
        "            'inference_time': inference_time\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"❌ Prediction with {model_name} failed: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def compare_model_predictions(img, models_dict, class_data, use_enhancement=False):\n",
        "    \"\"\"\n",
        "    Compare predictions across all available models\n",
        "\n",
        "    Args:\n",
        "        img: PIL Image\n",
        "        models_dict: Dictionary of loaded models\n",
        "        class_data: Class information\n",
        "        use_enhancement: Use enhancement ensemble\n",
        "\n",
        "    Returns:\n",
        "        dict: Results from all models\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "\n",
        "    # Get available models\n",
        "    available_models = [name for name, info in models_dict.items()\n",
        "                        if info.get('loaded', False)]\n",
        "\n",
        "    if not available_models:\n",
        "        st.error(\"❌ No models available for comparison\")\n",
        "        return None\n",
        "\n",
        "    # Progress tracking\n",
        "    progress_bar = st.progress(0)\n",
        "    status_text = st.empty()\n",
        "\n",
        "    for idx, model_name in enumerate(available_models):\n",
        "        status_text.text(f\"🔄 Running prediction with {model_name}...\")\n",
        "\n",
        "        result = predict_with_model(img, model_name, models_dict, class_data, use_enhancement)\n",
        "\n",
        "        if result:\n",
        "            results[model_name] = result\n",
        "\n",
        "        progress_bar.progress((idx + 1) / len(available_models))\n",
        "\n",
        "    status_text.text(\"✅ All predictions complete!\")\n",
        "    time.sleep(0.5)\n",
        "    status_text.empty()\n",
        "    progress_bar.empty()\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def display_comparison_results(results, class_data):\n",
        "    \"\"\"\n",
        "    Display comparison results from multiple models in a structured format\n",
        "\n",
        "    Args:\n",
        "        results: Dictionary of prediction results from multiple models\n",
        "        class_data: Class information (not used but kept for compatibility)\n",
        "    \"\"\"\n",
        "    if not results:\n",
        "        st.warning(\"⚠️ No results to compare\")\n",
        "        return\n",
        "\n",
        "    st.markdown(\"### 📊 Model Comparison Results\")\n",
        "\n",
        "    # Create comparison table\n",
        "    comparison_data = []\n",
        "    for model_name, result in results.items():\n",
        "        comparison_data.append({\n",
        "            'Model': model_name,\n",
        "            'Top Prediction': result['top3_classes'][0],\n",
        "            'Confidence': f\"{result['top3_probs'][0]:.2f}%\",\n",
        "            'Inference Time': f\"{result['inference_time']:.3f}s\"\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(comparison_data)\n",
        "    st.dataframe(df, use_container_width=True, hide_index=True)\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"#### 🎯 Top Predictions by Model\")\n",
        "\n",
        "    # Display individual model results\n",
        "    cols = st.columns(len(results))\n",
        "\n",
        "    for idx, (model_name, result) in enumerate(results.items()):\n",
        "        with cols[idx]:\n",
        "            st.markdown(f\"**{model_name}**\")\n",
        "\n",
        "            top_class = result['top3_classes'][0]\n",
        "            top_prob = result['top3_probs'][0]\n",
        "\n",
        "            # Dynamic color based on confidence\n",
        "            confidence_color = \"#4caf50\" if top_prob > 80 else \"#ff9800\" if top_prob > 60 else \"#f44336\"\n",
        "\n",
        "            st.markdown(f\"\"\"\n",
        "            <div style=\"background: white; padding: 1rem; border-radius: 10px;\n",
        "                        border-left: 4px solid {confidence_color};\n",
        "                        box-shadow: 0 2px 8px rgba(0,0,0,0.1);\">\n",
        "                <h4 style=\"margin: 0; color: #2e7d32;\">{top_class}</h4>\n",
        "                <h2 style=\"margin: 0.5rem 0; color: {confidence_color};\">{top_prob:.1f}%</h2>\n",
        "                <p style=\"margin: 0; font-size: 0.9rem; color: #666;\">\n",
        "                    ⏱️ Time: {result['inference_time']:.3f}s\n",
        "                </p>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "            st.markdown(\"**Top 3 Predictions:**\")\n",
        "            for i in range(min(3, len(result['top3_classes']))):  # FIXED: Handle edge cases\n",
        "                st.write(f\"{i + 1}. {result['top3_classes'][i]} ({result['top3_probs'][i]:.1f}%)\")\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"#### 🤝 Model Agreement Analysis\")\n",
        "\n",
        "    # Analyze agreement between models\n",
        "    top_predictions = [result['top3_classes'][0] for result in results.values()]\n",
        "\n",
        "    if len(set(top_predictions)) == 1:\n",
        "        st.success(f\"✅ **Perfect Agreement**: All models agree on **{top_predictions[0]}**\")\n",
        "        st.info(\"💡 High confidence in diagnosis - all models reached the same conclusion\")\n",
        "    else:\n",
        "        st.warning(\"⚠️ **Disagreement Detected**: Models have different top predictions\")\n",
        "\n",
        "        from collections import Counter\n",
        "        pred_counts = Counter(top_predictions)\n",
        "\n",
        "        st.write(\"**📊 Prediction Breakdown:**\")\n",
        "        for pred, count in pred_counts.most_common():\n",
        "            percentage = (count / len(results)) * 100\n",
        "            st.write(f\"- **{pred}**: {count}/{len(results)} models ({percentage:.0f}%)\")\n",
        "\n",
        "        # Provide recommendation based on consensus\n",
        "        most_common_pred, most_common_count = pred_counts.most_common(1)[0]\n",
        "        if most_common_count >= len(results) * 0.67:  # 2/3 majority\n",
        "            st.info(f\" **Recommendation**: Strong consensus ({most_common_count}/{len(results)}) favors **{most_common_pred}**\")\n",
        "        else:\n",
        "            st.warning(\" **Recommendation**: No strong consensus. Review image quality and consider retaking the photo for better results.\")\n",
        "\n",
        "    # Additional statistics\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"#### Performance Statistics\")\n",
        "\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "\n",
        "    with col1:\n",
        "        avg_confidence = sum(r['top3_probs'][0] for r in results.values()) / len(results)\n",
        "        st.metric(\"Average Confidence\", f\"{avg_confidence:.1f}%\")\n",
        "\n",
        "    with col2:\n",
        "        avg_time = sum(r['inference_time'] for r in results.values()) / len(results)\n",
        "        st.metric(\"Average Inference Time\", f\"{avg_time:.3f}s\")\n",
        "\n",
        "    with col3:\n",
        "        fastest_model = min(results.items(), key=lambda x: x[1]['inference_time'])\n",
        "        st.metric(\"Fastest Model\", fastest_model[0])"
      ],
      "id": "db5715f9a500c005",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "5d2edc279e3a6c74"
      },
      "cell_type": "markdown",
      "source": [
        "# Create Image with Prediction Overlay"
      ],
      "id": "5d2edc279e3a6c74"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-18T15:20:00.953243Z",
          "start_time": "2025-12-18T15:20:00.921238Z"
        },
        "id": "9c41d1eb297e98d3"
      },
      "cell_type": "code",
      "source": [
        "def create_prediction_image(img, prediction, confidence):\n",
        "    try:\n",
        "        img_copy = img.copy()\n",
        "\n",
        "        try:\n",
        "            font_large = ImageFont.truetype(\"arial.ttf\", 40)\n",
        "            font_small = ImageFont.truetype(\"arial.ttf\", 30)\n",
        "        except:\n",
        "            try:\n",
        "                font_large = ImageFont.truetype(\"Arial.ttf\", 40)\n",
        "                font_small = ImageFont.truetype(\"Arial.ttf\", 30)\n",
        "            except:\n",
        "                try:\n",
        "                    font_large = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", 40)\n",
        "                    font_small = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", 30)\n",
        "                except:\n",
        "                    font_large = ImageFont.load_default()\n",
        "                    font_small = ImageFont.load_default()\n",
        "\n",
        "        width, height = img_copy.size\n",
        "\n",
        "        overlay = Image.new('RGBA', img_copy.size, (0, 0, 0, 0))\n",
        "        overlay_draw = ImageDraw.Draw(overlay)\n",
        "\n",
        "        if confidence > 80:\n",
        "            color = (46, 125, 50, 220)\n",
        "        elif confidence > 60:\n",
        "            color = (255, 152, 0, 220)\n",
        "        else:\n",
        "            color = (244, 67, 54, 220)\n",
        "\n",
        "        overlay_draw.rectangle([(0, 0), (width, 140)], fill=color)\n",
        "\n",
        "        img_copy = img_copy.convert('RGBA')\n",
        "        img_copy = Image.alpha_composite(img_copy, overlay)\n",
        "        img_copy = img_copy.convert('RGB')\n",
        "\n",
        "        draw = ImageDraw.Draw(img_copy)\n",
        "\n",
        "        max_length = 35\n",
        "        display_prediction = prediction if len(prediction) <= max_length else prediction[:max_length] + \"...\"\n",
        "\n",
        "        draw.text((20, 20), f\"Prediction: {display_prediction}\",\n",
        "                  fill=(255, 255, 255), font=font_large)\n",
        "        draw.text((20, 80), f\"Confidence: {confidence:.1f}%\",\n",
        "                  fill=(255, 255, 255), font=font_small)\n",
        "\n",
        "        return img_copy\n",
        "\n",
        "    except Exception as e:\n",
        "        st.warning(f\"Could not create annotated image: {str(e)}\")\n",
        "        return img\n",
        "\n",
        "\n",
        "def create_comparison_grid(img, results, class_data=None):\n",
        "    try:\n",
        "        img_resized = img.resize((400, 400))\n",
        "\n",
        "        annotated_images = []\n",
        "\n",
        "        for model_name, result in results.items():\n",
        "            pred = result['top3_classes'][0]\n",
        "            conf = result['top3_probs'][0]\n",
        "\n",
        "            annotated = create_prediction_image(img_resized, f\"{model_name}: {pred}\", conf)\n",
        "            annotated_images.append(annotated)\n",
        "\n",
        "        n_models = len(annotated_images)\n",
        "\n",
        "        if n_models == 0:\n",
        "            return img\n",
        "        elif n_models == 1:\n",
        "            return annotated_images[0]\n",
        "        elif n_models == 2:\n",
        "            grid_width = 800\n",
        "            grid_height = 400\n",
        "            grid = Image.new('RGB', (grid_width, grid_height), (255, 255, 255))\n",
        "            grid.paste(annotated_images[0], (0, 0))\n",
        "            grid.paste(annotated_images[1], (400, 0))\n",
        "        else:\n",
        "            grid_width = 800\n",
        "            grid_height = 800\n",
        "            grid = Image.new('RGB', (grid_width, grid_height), (255, 255, 255))\n",
        "\n",
        "            grid.paste(annotated_images[0], (200, 0))\n",
        "\n",
        "            if len(annotated_images) > 1:\n",
        "                grid.paste(annotated_images[1], (0, 400))\n",
        "            if len(annotated_images) > 2:\n",
        "                grid.paste(annotated_images[2], (400, 400))\n",
        "\n",
        "        return grid\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Could not create comparison grid: {str(e)}\")\n",
        "        return img\n",
        "\n",
        "\n",
        "def create_detailed_report_image(img, result, class_data=None):\n",
        "    try:\n",
        "        canvas_width = 1200\n",
        "        canvas_height = 800\n",
        "        canvas = Image.new('RGB', (canvas_width, canvas_height), (255, 255, 255))\n",
        "        draw = ImageDraw.Draw(canvas)\n",
        "\n",
        "        try:\n",
        "            font_title = ImageFont.truetype(\"arial.ttf\", 36)\n",
        "            font_large = ImageFont.truetype(\"arial.ttf\", 28)\n",
        "            font_medium = ImageFont.truetype(\"arial.ttf\", 22)\n",
        "            font_small = ImageFont.truetype(\"arial.ttf\", 18)\n",
        "        except:\n",
        "            try:\n",
        "                font_title = ImageFont.truetype(\"Arial.ttf\", 36)\n",
        "                font_large = ImageFont.truetype(\"Arial.ttf\", 28)\n",
        "                font_medium = ImageFont.truetype(\"Arial.ttf\", 22)\n",
        "                font_small = ImageFont.truetype(\"Arial.ttf\", 18)\n",
        "            except:\n",
        "                font_title = font_large = font_medium = font_small = ImageFont.load_default()\n",
        "\n",
        "        draw.rectangle([(0, 0), (canvas_width, 80)], fill=(46, 125, 50))\n",
        "        draw.text((20, 20), \"Plant Disease Detection Report\",\n",
        "                  fill=(255, 255, 255), font=font_title)\n",
        "\n",
        "        img_display = img.resize((500, 500))\n",
        "        canvas.paste(img_display, (50, 120))\n",
        "\n",
        "        x_offset = 600\n",
        "        y_offset = 120\n",
        "\n",
        "        draw.text((x_offset, y_offset), f\"Model: {result['model_name']}\",\n",
        "                  fill=(46, 125, 50), font=font_large)\n",
        "        y_offset += 50\n",
        "\n",
        "        draw.text((x_offset, y_offset), \"Top Diagnosis:\",\n",
        "                  fill=(0, 0, 0), font=font_medium)\n",
        "        y_offset += 35\n",
        "\n",
        "        top_pred = result['top3_classes'][0]\n",
        "        if len(top_pred) > 30:\n",
        "            top_pred = top_pred[:27] + \"...\"\n",
        "        draw.text((x_offset + 20, y_offset), top_pred,\n",
        "                  fill=(46, 125, 50), font=font_large)\n",
        "        y_offset += 45\n",
        "\n",
        "        conf = result['top3_probs'][0]\n",
        "        conf_color = (46, 125, 50) if conf > 80 else (255, 152, 0) if conf > 60 else (244, 67, 54)\n",
        "\n",
        "        draw.text((x_offset + 20, y_offset), f\"Confidence: {conf:.2f}%\",\n",
        "                  fill=conf_color, font=font_large)\n",
        "        y_offset += 60\n",
        "\n",
        "        draw.text((x_offset, y_offset), \"Top 3 Predictions:\",\n",
        "                  fill=(0, 0, 0), font=font_medium)\n",
        "        y_offset += 40\n",
        "\n",
        "        for i in range(min(3, len(result['top3_classes']))):\n",
        "            medal = \"1\" if i == 0 else \"2\" if i == 1 else \"3\"\n",
        "            pred_text = result['top3_classes'][i]\n",
        "            if len(pred_text) > 25:\n",
        "                pred_text = pred_text[:22] + \"...\"\n",
        "            text = f\"{medal}. {pred_text}: {result['top3_probs'][i]:.2f}%\"\n",
        "            draw.text((x_offset + 20, y_offset), text,\n",
        "                      fill=(0, 0, 0), font=font_small)\n",
        "            y_offset += 35\n",
        "\n",
        "        y_offset += 20\n",
        "        draw.text((x_offset, y_offset),\n",
        "                  f\"Processing Time: {result['inference_time']:.3f}s\",\n",
        "                  fill=(0, 0, 0), font=font_small)\n",
        "\n",
        "        draw.rectangle([(0, canvas_height - 60), (canvas_width, canvas_height)],\n",
        "                       fill=(200, 230, 201))\n",
        "        draw.text((20, canvas_height - 45),\n",
        "                  f\"Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
        "                  fill=(0, 0, 0), font=font_small)\n",
        "        draw.text((canvas_width - 400, canvas_height - 45),\n",
        "                  \"Plant Disease Detection System v1.0\",\n",
        "                  fill=(0, 0, 0), font=font_small)\n",
        "\n",
        "        return canvas\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Could not create report image: {str(e)}\")\n",
        "        return img\n",
        "\n",
        "\n",
        "def export_results_package(img, result, class_data=None):\n",
        "    try:\n",
        "        import zipfile\n",
        "\n",
        "        zip_buffer = BytesIO()\n",
        "\n",
        "        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:\n",
        "            img_buffer = BytesIO()\n",
        "            img.save(img_buffer, format='PNG')\n",
        "            zip_file.writestr('original_image.png', img_buffer.getvalue())\n",
        "\n",
        "            annotated = create_prediction_image(\n",
        "                img,\n",
        "                result['top3_classes'][0],\n",
        "                result['top3_probs'][0]\n",
        "            )\n",
        "            annotated_buffer = BytesIO()\n",
        "            annotated.save(annotated_buffer, format='PNG')\n",
        "            zip_file.writestr('annotated_image.png', annotated_buffer.getvalue())\n",
        "\n",
        "            if result.get('heatmap') is not None:\n",
        "                try:\n",
        "                    img_array = np.array(img.resize(IMG_SIZE))\n",
        "                    _, heatmap_colored, overlay = create_gradcam_visualization(img_array, result['heatmap'])\n",
        "                    gradcam_pil = Image.fromarray(overlay)\n",
        "                    gradcam_buffer = BytesIO()\n",
        "                    gradcam_pil.save(gradcam_buffer, format='PNG')\n",
        "                    zip_file.writestr('gradcam_visualization.png', gradcam_buffer.getvalue())\n",
        "                except Exception as e:\n",
        "                    st.warning(f\"Could not generate Grad-CAM visualization: {str(e)}\")\n",
        "\n",
        "            report_img = create_detailed_report_image(img, result, class_data)\n",
        "            report_buffer = BytesIO()\n",
        "            report_img.save(report_buffer, format='PNG')\n",
        "            zip_file.writestr('detailed_report.png', report_buffer.getvalue())\n",
        "\n",
        "            json_data = {\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'model': result['model_name'],\n",
        "                'top_prediction': result['top3_classes'][0],\n",
        "                'confidence': float(result['top3_probs'][0]),\n",
        "                'top3_predictions': [\n",
        "                    {\n",
        "                        'class': result['top3_classes'][i],\n",
        "                        'confidence': float(result['top3_probs'][i])\n",
        "                    } for i in range(min(3, len(result['top3_classes'])))\n",
        "                ],\n",
        "                'inference_time': float(result['inference_time'])\n",
        "            }\n",
        "            zip_file.writestr('results.json', json.dumps(json_data, indent=2))\n",
        "\n",
        "            text_report = f\"\"\"\n",
        "Plant Disease Detection Report\n",
        "{'=' * 50}\n",
        "\n",
        "Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "Model: {result['model_name']}\n",
        "\n",
        "PRIMARY DIAGNOSIS:\n",
        "{result['top3_classes'][0]}\n",
        "Confidence: {result['top3_probs'][0]:.2f}%\n",
        "\n",
        "TOP 3 PREDICTIONS:\n",
        "1. {result['top3_classes'][0]} - {result['top3_probs'][0]:.2f}%\n",
        "2. {result['top3_classes'][1]} - {result['top3_probs'][1]:.2f}%\n",
        "3. {result['top3_classes'][2]} - {result['top3_probs'][2]:.2f}%\n",
        "\n",
        "PERFORMANCE:\n",
        "Processing Time: {result['inference_time']:.3f} seconds\n",
        "\n",
        "RECOMMENDATIONS:\n",
        "- Consult with agricultural expert for confirmation\n",
        "- Monitor plant condition regularly\n",
        "- Follow appropriate treatment protocols\n",
        "\n",
        "{'=' * 50}\n",
        "Generated by Plant Disease Detection System v1.0\n",
        "            \"\"\"\n",
        "            zip_file.writestr('report.txt', text_report)\n",
        "\n",
        "        zip_buffer.seek(0)\n",
        "        return zip_buffer\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Could not create results package: {str(e)}\")\n",
        "        return None"
      ],
      "id": "9c41d1eb297e98d3",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "ebbb1ff778888b2b"
      },
      "cell_type": "markdown",
      "source": [
        "# Batch Processing Feature (BONUS)"
      ],
      "id": "ebbb1ff778888b2b"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-18T15:20:00.994393Z",
          "start_time": "2025-12-18T15:20:00.962902Z"
        },
        "id": "3600ac39443cf8aa"
      },
      "cell_type": "code",
      "source": [
        "def batch_process_images(uploaded_files, models_dict, selected_model, class_data,\n",
        "                         use_enhancement=False, save_visualizations=False):\n",
        "    if not uploaded_files:\n",
        "        st.warning(\"No files uploaded\")\n",
        "        return [], {}\n",
        "\n",
        "    results = []\n",
        "    visualizations = {} if save_visualizations else None\n",
        "\n",
        "    if selected_model not in models_dict or not models_dict[selected_model].get('loaded', False):\n",
        "        st.error(f\"Model {selected_model} not available\")\n",
        "        return [], {}\n",
        "\n",
        "    model = models_dict[selected_model]['model']\n",
        "    preprocess_fn = models_dict[selected_model]['preprocess']\n",
        "\n",
        "    progress_bar = st.progress(0)\n",
        "    status_text = st.empty()\n",
        "\n",
        "    start_time = time.time()\n",
        "    successful = 0\n",
        "    failed = 0\n",
        "\n",
        "    for idx, file in enumerate(uploaded_files):\n",
        "        try:\n",
        "            status_text.text(f\"Processing image {idx + 1}/{len(uploaded_files)}: {file.name}\")\n",
        "\n",
        "            img = Image.open(file).convert('RGB')\n",
        "\n",
        "            top3_classes, top3_probs, heatmap, all_preds = predict_disease(\n",
        "                img, model, class_data, preprocess_fn, use_enhancement\n",
        "            )\n",
        "\n",
        "            if top3_classes is None:\n",
        "                failed += 1\n",
        "                results.append({\n",
        "                    'filename': file.name,\n",
        "                    'status': 'Failed',\n",
        "                    'prediction': 'N/A',\n",
        "                    'confidence': 0.0,\n",
        "                    'top3_classes': [],\n",
        "                    'top3_probs': []\n",
        "                })\n",
        "                continue\n",
        "\n",
        "            result = {\n",
        "                'filename': file.name,\n",
        "                'status': 'Success',\n",
        "                'prediction': top3_classes[0],\n",
        "                'confidence': top3_probs[0],\n",
        "                'top3_classes': top3_classes,\n",
        "                'top3_probs': top3_probs,\n",
        "                'file_size': file.size / 1024,\n",
        "                'image_size': f\"{img.width}×{img.height}\"\n",
        "            }\n",
        "\n",
        "            results.append(result)\n",
        "            successful += 1\n",
        "\n",
        "            if save_visualizations and heatmap is not None:\n",
        "                img_array = np.array(img.resize(IMG_SIZE))\n",
        "                _, heatmap_colored, overlay = create_gradcam_visualization(img_array, heatmap)\n",
        "                visualizations[file.name] = {\n",
        "                    'original': img,\n",
        "                    'heatmap': heatmap_colored,\n",
        "                    'overlay': overlay,\n",
        "                    'prediction': top3_classes[0],\n",
        "                    'confidence': top3_probs[0]\n",
        "                }\n",
        "\n",
        "        except Exception as e:\n",
        "            failed += 1\n",
        "            st.warning(f\"Failed to process {file.name}: {str(e)}\")\n",
        "            results.append({\n",
        "                'filename': file.name,\n",
        "                'status': 'Error',\n",
        "                'prediction': 'Error',\n",
        "                'confidence': 0.0,\n",
        "                'error': str(e)\n",
        "            })\n",
        "\n",
        "        progress_bar.progress((idx + 1) / len(uploaded_files))\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    avg_time = total_time / len(uploaded_files) if uploaded_files else 0\n",
        "\n",
        "    status_text.empty()\n",
        "    progress_bar.empty()\n",
        "\n",
        "    st.success(\"Batch processing complete!\")\n",
        "\n",
        "    col1, col2, col3, col4 = st.columns(4)\n",
        "    with col1:\n",
        "        st.metric(\"Total Images\", len(uploaded_files))\n",
        "    with col2:\n",
        "        st.metric(\"Successful\", successful, delta=f\"{successful / len(uploaded_files) * 100:.0f}%\")\n",
        "    with col3:\n",
        "        st.metric(\"Failed\", failed, delta=f\"-{failed / len(uploaded_files) * 100:.0f}%\" if failed > 0 else \"0%\")\n",
        "    with col4:\n",
        "        st.metric(\"Avg Time\", f\"{avg_time:.2f}s\", delta=f\"{total_time:.1f}s total\")\n",
        "\n",
        "    return results, visualizations\n",
        "\n",
        "\n",
        "def display_batch_results(results, visualizations=None):\n",
        "    if not results:\n",
        "        st.warning(\"No results to display\")\n",
        "        return\n",
        "\n",
        "    st.markdown(\"### Batch Processing Results\")\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "    column_order = ['filename', 'status', 'prediction', 'confidence']\n",
        "    if 'image_size' in df.columns:\n",
        "        column_order.append('image_size')\n",
        "    if 'file_size' in df.columns:\n",
        "        column_order.append('file_size')\n",
        "\n",
        "    df = df[column_order]\n",
        "\n",
        "    if 'confidence' in df.columns:\n",
        "        df['confidence'] = df['confidence'].apply(lambda x: f\"{x:.2f}%\" if x > 0 else \"N/A\")\n",
        "\n",
        "    st.dataframe(df, use_container_width=True, hide_index=True)\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"### Analysis Summary\")\n",
        "\n",
        "    successful_results = [r for r in results if r.get('status') == 'Success']\n",
        "\n",
        "    if successful_results:\n",
        "        from collections import Counter\n",
        "        predictions = [r['prediction'] for r in successful_results]\n",
        "        pred_counts = Counter(predictions)\n",
        "\n",
        "        st.markdown(\"#### Disease Distribution\")\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "        diseases = list(pred_counts.keys())\n",
        "        counts = list(pred_counts.values())\n",
        "\n",
        "        bars = ax.barh(diseases, counts, color='#66bb6a')\n",
        "        ax.set_xlabel('Number of Images', fontweight='bold')\n",
        "        ax.set_title('Detected Diseases Distribution', fontweight='bold', fontsize=14)\n",
        "        ax.grid(axis='x', alpha=0.3)\n",
        "\n",
        "        for i, (disease, count) in enumerate(zip(diseases, counts)):\n",
        "            ax.text(count + 0.1, i, str(count), va='center', fontweight='bold')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        st.pyplot(fig)\n",
        "        plt.close()\n",
        "\n",
        "        st.markdown(\"#### Confidence Distribution\")\n",
        "\n",
        "        confidences = [r['confidence'] for r in successful_results]\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(10, 5))\n",
        "        ax.hist(confidences, bins=20, color='#4caf50', alpha=0.7, edgecolor='black')\n",
        "        ax.set_xlabel('Confidence (%)', fontweight='bold')\n",
        "        ax.set_ylabel('Number of Images', fontweight='bold')\n",
        "        ax.set_title('Prediction Confidence Distribution', fontweight='bold', fontsize=14)\n",
        "        ax.axvline(x=np.mean(confidences), color='red', linestyle='--',\n",
        "                   label=f'Mean: {np.mean(confidences):.1f}%')\n",
        "        ax.axvline(x=np.median(confidences), color='blue', linestyle='--',\n",
        "                   label=f'Median: {np.median(confidences):.1f}%')\n",
        "        ax.legend()\n",
        "        ax.grid(alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        st.pyplot(fig)\n",
        "        plt.close()\n",
        "\n",
        "        col1, col2, col3 = st.columns(3)\n",
        "        with col1:\n",
        "            st.metric(\"Avg Confidence\", f\"{np.mean(confidences):.1f}%\")\n",
        "        with col2:\n",
        "            st.metric(\"Median Confidence\", f\"{np.median(confidences):.1f}%\")\n",
        "        with col3:\n",
        "            high_conf = sum(1 for c in confidences if c > 80)\n",
        "            st.metric(\"High Confidence (>80%)\", f\"{high_conf}/{len(confidences)}\")\n",
        "\n",
        "    if visualizations:\n",
        "        st.markdown(\"---\")\n",
        "        st.markdown(\"### Visualization Gallery\")\n",
        "\n",
        "        n_cols = 3\n",
        "        viz_items = list(visualizations.items())\n",
        "\n",
        "        for i in range(0, len(viz_items), n_cols):\n",
        "            cols = st.columns(n_cols)\n",
        "\n",
        "            for j, col in enumerate(cols):\n",
        "                if i + j < len(viz_items):\n",
        "                    filename, viz_data = viz_items[i + j]\n",
        "\n",
        "                    with col:\n",
        "                        with st.expander(f\"{filename}\", expanded=False):\n",
        "                            st.image(viz_data['original'], caption=\"Original\",\n",
        "                                     use_container_width=True)\n",
        "                            if 'heatmap' in viz_data:\n",
        "                                st.image(viz_data['heatmap'], caption=\"Heatmap\",\n",
        "                                         use_container_width=True)\n",
        "                            if 'overlay' in viz_data:\n",
        "                                st.image(viz_data['overlay'], caption=\"Overlay\",\n",
        "                                         use_container_width=True)\n",
        "                            st.write(f\"**{viz_data['prediction']}**\")\n",
        "                            st.write(f\"Confidence: {viz_data['confidence']:.1f}%\")\n",
        "\n",
        "\n",
        "def export_batch_results(results, format='csv'):\n",
        "    if not results:\n",
        "        st.warning(\"No results to export\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        if format == 'csv':\n",
        "            df = pd.DataFrame(results)\n",
        "            buffer = BytesIO()\n",
        "            df.to_csv(buffer, index=False)\n",
        "            buffer.seek(0)\n",
        "            return buffer\n",
        "\n",
        "        elif format == 'json':\n",
        "            json_str = json.dumps(results, indent=2)\n",
        "            buffer = BytesIO()\n",
        "            buffer.write(json_str.encode())\n",
        "            buffer.seek(0)\n",
        "            return buffer\n",
        "\n",
        "        elif format == 'excel':\n",
        "            df = pd.DataFrame(results)\n",
        "            buffer = BytesIO()\n",
        "            with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:\n",
        "                df.to_excel(writer, sheet_name='Results', index=False)\n",
        "\n",
        "                workbook = writer.book\n",
        "                worksheet = writer.sheets['Results']\n",
        "\n",
        "                header_format = workbook.add_format({\n",
        "                    'bold': True,\n",
        "                    'bg_color': '#4caf50',\n",
        "                    'font_color': 'white',\n",
        "                    'border': 1\n",
        "                })\n",
        "\n",
        "                for col_num, value in enumerate(df.columns.values):\n",
        "                    worksheet.write(0, col_num, value, header_format)\n",
        "\n",
        "                for i, col in enumerate(df.columns):\n",
        "                    max_len = max(df[col].astype(str).apply(len).max(), len(col)) + 2\n",
        "                    worksheet.set_column(i, i, max_len)\n",
        "\n",
        "            buffer.seek(0)\n",
        "            return buffer\n",
        "\n",
        "        else:\n",
        "            st.error(f\"Unsupported format: {format}\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Export failed: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def create_batch_report_pdf(results, visualizations=None):\n",
        "    st.info(\"PDF report generation would require additional libraries (reportlab)\")\n",
        "    st.info(\"For now, you can export to Excel or CSV formats\")"
      ],
      "id": "3600ac39443cf8aa",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "3d06e8420ddf18c9"
      },
      "cell_type": "markdown",
      "source": [
        "# Real-time Video Processing (BONUS)"
      ],
      "id": "3d06e8420ddf18c9"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-18T15:20:01.035638Z",
          "start_time": "2025-12-18T15:20:01.003277Z"
        },
        "id": "db6cc77860843904"
      },
      "cell_type": "code",
      "source": [
        "def process_video_frame(frame, model, class_data, preprocess_fn=None):\n",
        "    try:\n",
        "        if preprocess_fn is None:\n",
        "            preprocess_fn = tf.keras.applications.resnet50.preprocess_input\n",
        "\n",
        "        img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "        img_resized = img.resize(IMG_SIZE)\n",
        "        img_array = tf.keras.preprocessing.image.img_to_array(img_resized)\n",
        "        img_array = preprocess_fn(img_array)\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "        predictions = model.predict(img_array, verbose=0)\n",
        "        top_idx = np.argmax(predictions[0])\n",
        "\n",
        "        # FIXED: Handle different class_data structures\n",
        "        try:\n",
        "            if 'formatted_names' in class_data:\n",
        "                top_class = class_data['formatted_names'][top_idx]\n",
        "            elif str(top_idx) in class_data:\n",
        "                top_class = class_data[str(top_idx)]['name']\n",
        "            elif isinstance(class_data, list):\n",
        "                top_class = class_data[top_idx]\n",
        "            else:\n",
        "                top_class = f\"Class_{top_idx}\"\n",
        "        except (KeyError, IndexError):\n",
        "            top_class = f\"Class_{top_idx}\"\n",
        "\n",
        "        top_prob = float(predictions[0][top_idx]) * 100\n",
        "\n",
        "        return top_class, top_prob\n",
        "\n",
        "    except Exception as e:\n",
        "        return \"Error\", 0.0\n",
        "\n",
        "\n",
        "def annotate_frame(frame, prediction, confidence, fps=0):\n",
        "    try:\n",
        "        frame_copy = frame.copy()\n",
        "        h, w = frame_copy.shape[:2]\n",
        "\n",
        "        if confidence > 80:\n",
        "            color = (76, 175, 80)\n",
        "        elif confidence > 60:\n",
        "            color = (0, 152, 255)\n",
        "        else:\n",
        "            color = (54, 67, 244)\n",
        "\n",
        "        overlay = frame_copy.copy()\n",
        "        cv2.rectangle(overlay, (0, 0), (w, 100), color, -1)\n",
        "        cv2.addWeighted(overlay, 0.4, frame_copy, 0.6, 0, frame_copy)\n",
        "\n",
        "        cv2.rectangle(frame_copy, (0, 0), (w, 100), color, 3)\n",
        "\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "\n",
        "        pred_text = f\"Disease: {prediction[:30]}\"\n",
        "        cv2.putText(frame_copy, pred_text, (15, 35),\n",
        "                    font, 0.8, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "        conf_text = f\"Confidence: {confidence:.1f}%\"\n",
        "        cv2.putText(frame_copy, conf_text, (15, 70),\n",
        "                    font, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "        if fps > 0:\n",
        "            fps_text = f\"FPS: {fps:.1f}\"\n",
        "            text_size = cv2.getTextSize(fps_text, font, 0.6, 2)[0]\n",
        "            cv2.putText(frame_copy, fps_text,\n",
        "                        (w - text_size[0] - 15, 30),\n",
        "                        font, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "        return frame_copy\n",
        "\n",
        "    except Exception as e:\n",
        "        return frame\n",
        "\n",
        "\n",
        "def webcam_realtime_detection(models_dict, selected_model, class_data,\n",
        "                              confidence_threshold=60.0, show_fps=True):\n",
        "    st.markdown(\"### Real-Time Webcam Detection\")\n",
        "\n",
        "    if selected_model not in models_dict or not models_dict[selected_model].get('loaded', False):\n",
        "        st.error(f\"Model {selected_model} not available\")\n",
        "        return\n",
        "\n",
        "    model = models_dict[selected_model]['model']\n",
        "    preprocess_fn = models_dict[selected_model]['preprocess']\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "    <div class=\"info-box\">\n",
        "    <b>Instructions:</b>\n",
        "    <ul>\n",
        "        <li>Click 'Take a picture' to capture a frame</li>\n",
        "        <li>Position the leaf clearly in view</li>\n",
        "        <li>Ensure good lighting for best results</li>\n",
        "        <li>The prediction will appear below</li>\n",
        "    </ul>\n",
        "    </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    img_file = st.camera_input(\"Capture Plant Leaf\")\n",
        "\n",
        "    if img_file is not None:\n",
        "        img = Image.open(img_file).convert('RGB')\n",
        "\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            st.markdown(\"**Captured Image**\")\n",
        "            st.image(img, use_container_width=True)\n",
        "\n",
        "        with col2:\n",
        "            st.markdown(\"**Real-Time Prediction**\")\n",
        "\n",
        "            with st.spinner(\"Analyzing...\"):\n",
        "                start_time = time.time()\n",
        "\n",
        "                top3_classes, top3_probs, heatmap, all_preds = predict_disease(\n",
        "                    img, model, class_data, preprocess_fn\n",
        "                )\n",
        "\n",
        "                inference_time = time.time() - start_time\n",
        "\n",
        "            if top3_classes:\n",
        "                confidence = top3_probs[0]\n",
        "                prediction = top3_classes[0]\n",
        "\n",
        "                st.markdown(f\"\"\"\n",
        "                <div class=\"prediction-card\">\n",
        "                    <h2 style=\"color: #2e7d32; margin: 0;\">{prediction}</h2>\n",
        "                    <h1 style=\"color: #43a047; margin: 0.5rem 0; font-size: 3rem;\">\n",
        "                        {confidence:.1f}%\n",
        "                    </h1>\n",
        "                    <p style=\"color: #666; margin: 0;\">\n",
        "                        Processed in {inference_time:.2f}s\n",
        "                    </p>\n",
        "                </div>\n",
        "                \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                st.markdown(\"**Top 3 Predictions:**\")\n",
        "                for i in range(min(3, len(top3_classes))):\n",
        "                    st.write(f\"{top3_classes[i]}: **{top3_probs[i]:.1f}%**\")\n",
        "\n",
        "\n",
        "def video_file_processing(uploaded_video, models_dict, selected_model, class_data,\n",
        "                          process_every_n_frames=5, max_frames=100):\n",
        "    st.markdown(\"### Video File Processing\")\n",
        "\n",
        "    if selected_model not in models_dict or not models_dict[selected_model].get('loaded', False):\n",
        "        st.error(f\"Model {selected_model} not available\")\n",
        "        return None\n",
        "\n",
        "    model = models_dict[selected_model]['model']\n",
        "    preprocess_fn = models_dict[selected_model]['preprocess']\n",
        "\n",
        "    try:\n",
        "        import tempfile\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:\n",
        "            tmp_file.write(uploaded_video.read())\n",
        "            video_path = tmp_file.name\n",
        "\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "        if not cap.isOpened():\n",
        "            st.error(\"Could not open video file\")\n",
        "            if os.path.exists(video_path):\n",
        "                os.unlink(video_path)\n",
        "            return None\n",
        "\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "        st.info(f\"Video Info: {total_frames} frames @ {fps:.1f} FPS\")\n",
        "\n",
        "        frames_to_process = min(total_frames // process_every_n_frames, max_frames)\n",
        "\n",
        "        st.warning(f\"Processing every {process_every_n_frames} frames (total: {frames_to_process} frames)\")\n",
        "\n",
        "        results = []\n",
        "        progress_bar = st.progress(0)\n",
        "        status_text = st.empty()\n",
        "\n",
        "        frame_idx = 0\n",
        "        processed_idx = 0\n",
        "\n",
        "        while cap.isOpened() and processed_idx < frames_to_process:\n",
        "            ret, frame = cap.read()\n",
        "\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            if frame_idx % process_every_n_frames == 0:\n",
        "                status_text.text(f\"Processing frame {processed_idx + 1}/{frames_to_process}\")\n",
        "\n",
        "                top_class, top_prob = process_video_frame(frame, model, class_data, preprocess_fn)\n",
        "\n",
        "                results.append({\n",
        "                    'frame': frame_idx,\n",
        "                    'time': frame_idx / fps if fps > 0 else 0,\n",
        "                    'prediction': top_class,\n",
        "                    'confidence': top_prob\n",
        "                })\n",
        "\n",
        "                processed_idx += 1\n",
        "                progress_bar.progress(processed_idx / frames_to_process)\n",
        "\n",
        "            frame_idx += 1\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "        if os.path.exists(video_path):\n",
        "            try:\n",
        "                os.unlink(video_path)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        status_text.empty()\n",
        "        progress_bar.empty()\n",
        "\n",
        "        st.success(f\"Processed {len(results)} frames!\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Video processing failed: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def display_video_results(results):\n",
        "    if not results:\n",
        "        st.warning(\"No results to display\")\n",
        "        return\n",
        "\n",
        "    st.markdown(\"### Video Analysis Results\")\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "    st.markdown(\"#### Prediction Timeline\")\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "    scatter = ax.scatter(df['time'], df['confidence'],\n",
        "                         c=df['confidence'], cmap='RdYlGn',\n",
        "                         s=100, alpha=0.6, edgecolors='black')\n",
        "\n",
        "    ax.set_xlabel('Time (seconds)', fontweight='bold', fontsize=12)\n",
        "    ax.set_ylabel('Confidence (%)', fontweight='bold', fontsize=12)\n",
        "    ax.set_title('Prediction Confidence Over Time', fontweight='bold', fontsize=14)\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "    cbar = plt.colorbar(scatter, ax=ax)\n",
        "    cbar.set_label('Confidence (%)', fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    st.pyplot(fig)\n",
        "    plt.close()\n",
        "\n",
        "    st.markdown(\"#### Disease Distribution in Video\")\n",
        "\n",
        "    from collections import Counter\n",
        "    pred_counts = Counter(df['prediction'])\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    diseases = list(pred_counts.keys())\n",
        "    counts = list(pred_counts.values())\n",
        "\n",
        "    bars = ax.barh(diseases, counts, color='#66bb6a')\n",
        "    ax.set_xlabel('Number of Frames', fontweight='bold')\n",
        "    ax.set_title('Detected Diseases in Video', fontweight='bold', fontsize=14)\n",
        "    ax.grid(axis='x', alpha=0.3)\n",
        "\n",
        "    for i, (disease, count) in enumerate(zip(diseases, counts)):\n",
        "        percentage = (count / len(results)) * 100\n",
        "        ax.text(count + 0.5, i, f\"{count} ({percentage:.1f}%)\",\n",
        "                va='center', fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    st.pyplot(fig)\n",
        "    plt.close()\n",
        "\n",
        "    st.markdown(\"#### Statistics\")\n",
        "\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "\n",
        "    with col1:\n",
        "        st.metric(\"Avg Confidence\", f\"{df['confidence'].mean():.1f}%\")\n",
        "    with col2:\n",
        "        most_common = pred_counts.most_common(1)[0]\n",
        "        pred_display = most_common[0][:20] if len(most_common[0]) > 20 else most_common[0]\n",
        "        st.metric(\"Most Common\", pred_display,\n",
        "                  delta=f\"{most_common[1]} frames\")\n",
        "    with col3:\n",
        "        high_conf_frames = len(df[df['confidence'] > 80])\n",
        "        st.metric(\"High Confidence\", f\"{high_conf_frames}/{len(df)}\",\n",
        "                  delta=f\"{high_conf_frames / len(df) * 100:.0f}%\")\n",
        "\n",
        "    with st.expander(\"View Detailed Frame Data\"):\n",
        "        st.dataframe(df, use_container_width=True)"
      ],
      "id": "db6cc77860843904",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "bd3664ab291a454f"
      },
      "cell_type": "markdown",
      "source": [
        "# Confusion Matrix with Real Data"
      ],
      "id": "bd3664ab291a454f"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-18T15:20:01.075441Z",
          "start_time": "2025-12-18T15:20:01.045196Z"
        },
        "id": "1271392ff81c5634"
      },
      "cell_type": "code",
      "source": [
        "def show_confusion_matrix(actual_cm=None, class_names=None):\n",
        "    st.markdown(\"### Model Performance - Confusion Matrix\")\n",
        "\n",
        "    if actual_cm is None:\n",
        "        st.markdown(\"\"\"\n",
        "        <div class=\"info-box\">\n",
        "        <b>Load Your Test Results</b><br>\n",
        "        Upload a confusion matrix file (.npy format) to display actual model performance.\n",
        "        If no file is uploaded, sample data will be shown for demonstration.\n",
        "        </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        cm_file = st.file_uploader(\n",
        "            \"Upload confusion matrix (numpy .npy file)\",\n",
        "            type=['npy'],\n",
        "            help=\"Upload a saved numpy array containing the confusion matrix\"\n",
        "        )\n",
        "\n",
        "        if cm_file is not None:\n",
        "            try:\n",
        "                cm = np.load(cm_file)\n",
        "                st.success(\"Confusion matrix loaded successfully!\")\n",
        "            except Exception as e:\n",
        "                st.error(f\"Error loading file: {str(e)}\")\n",
        "                return\n",
        "        else:\n",
        "            num_classes = 15 if class_names is None else len(class_names)\n",
        "            cm = np.random.randint(5, 50, size=(num_classes, num_classes))\n",
        "            np.fill_diagonal(cm, np.random.randint(80, 150, size=num_classes))\n",
        "\n",
        "            st.warning(\"Showing sample data. Upload actual test results for real metrics.\")\n",
        "    else:\n",
        "        cm = actual_cm\n",
        "        st.success(\"Using provided confusion matrix\")\n",
        "\n",
        "    num_classes = cm.shape[0]\n",
        "\n",
        "    if class_names is None or len(class_names) != num_classes:\n",
        "        class_names = [f\"Class {i}\" for i in range(num_classes)]\n",
        "\n",
        "    display_names = [name[:15] + \"...\" if len(name) > 15 else name\n",
        "                     for name in class_names]\n",
        "\n",
        "    st.markdown(\"#### Confusion Matrix Heatmap\")\n",
        "\n",
        "    figsize = (max(12, num_classes * 0.8), max(10, num_classes * 0.7))\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', ax=ax,\n",
        "                cbar_kws={'label': 'Count'}, linewidths=0.5,\n",
        "                xticklabels=display_names, yticklabels=display_names,\n",
        "                square=True)\n",
        "\n",
        "    ax.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
        "    ax.set_ylabel('True Label', fontsize=12, fontweight='bold')\n",
        "    ax.set_title('Confusion Matrix - Disease Classification',\n",
        "                 fontsize=14, fontweight='bold', pad=20)\n",
        "\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.yticks(rotation=0)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    st.pyplot(fig)\n",
        "    plt.close()\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"### Performance Metrics\")\n",
        "\n",
        "    accuracy = np.trace(cm) / np.sum(cm) * 100\n",
        "\n",
        "    precision_per_class = []\n",
        "    recall_per_class = []\n",
        "    f1_per_class = []\n",
        "\n",
        "    for i in range(num_classes):\n",
        "        tp = cm[i, i]\n",
        "        fp = np.sum(cm[:, i]) - tp\n",
        "        fn = np.sum(cm[i, :]) - tp\n",
        "        tn = np.sum(cm) - tp - fp - fn\n",
        "\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        precision_per_class.append(precision * 100)\n",
        "\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        recall_per_class.append(recall * 100)\n",
        "\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "        f1_per_class.append(f1 * 100)\n",
        "\n",
        "    macro_precision = np.mean(precision_per_class)\n",
        "    macro_recall = np.mean(recall_per_class)\n",
        "    macro_f1 = np.mean(f1_per_class)\n",
        "\n",
        "    col1, col2, col3, col4 = st.columns(4)\n",
        "\n",
        "    with col1:\n",
        "        st.metric(\"Overall Accuracy\", f\"{accuracy:.2f}%\",\n",
        "                  help=\"Percentage of correct predictions\")\n",
        "    with col2:\n",
        "        st.metric(\"Macro Precision\", f\"{macro_precision:.2f}%\",\n",
        "                  help=\"Average precision across all classes\")\n",
        "    with col3:\n",
        "        st.metric(\"Macro Recall\", f\"{macro_recall:.2f}%\",\n",
        "                  help=\"Average recall across all classes\")\n",
        "    with col4:\n",
        "        st.metric(\"Macro F1-Score\", f\"{macro_f1:.2f}%\",\n",
        "                  help=\"Harmonic mean of precision and recall\")\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"#### Per-Class Performance\")\n",
        "\n",
        "    metrics_df = pd.DataFrame({\n",
        "        'Class': class_names,\n",
        "        'Precision (%)': [f\"{p:.2f}\" for p in precision_per_class],\n",
        "        'Recall (%)': [f\"{r:.2f}\" for r in recall_per_class],\n",
        "        'F1-Score (%)': [f\"{f:.2f}\" for f in f1_per_class],\n",
        "        'Support': [np.sum(cm[i, :]) for i in range(num_classes)]\n",
        "    })\n",
        "\n",
        "    st.dataframe(metrics_df, use_container_width=True, hide_index=True)\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"#### Per-Class Metrics Visualization\")\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "    x = np.arange(num_classes)\n",
        "    width = 0.25\n",
        "\n",
        "    ax1.bar(x - width, precision_per_class, width, label='Precision',\n",
        "            color='#66bb6a', alpha=0.8)\n",
        "    ax1.bar(x, recall_per_class, width, label='Recall',\n",
        "            color='#42a5f5', alpha=0.8)\n",
        "    ax1.bar(x + width, f1_per_class, width, label='F1-Score',\n",
        "            color='#ffa726', alpha=0.8)\n",
        "\n",
        "    ax1.set_xlabel('Class', fontweight='bold')\n",
        "    ax1.set_ylabel('Score (%)', fontweight='bold')\n",
        "    ax1.set_title('Precision, Recall, and F1-Score by Class',\n",
        "                  fontweight='bold', fontsize=13)\n",
        "    ax1.set_xticks(x)\n",
        "    ax1.set_xticklabels(display_names, rotation=45, ha='right')\n",
        "    ax1.legend()\n",
        "    ax1.grid(axis='y', alpha=0.3)\n",
        "    ax1.set_ylim(0, 105)\n",
        "\n",
        "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    sns.heatmap(cm_normalized, annot=False, cmap='RdYlGn', ax=ax2,\n",
        "                cbar_kws={'label': 'Proportion'}, linewidths=0.5,\n",
        "                xticklabels=display_names, yticklabels=display_names,\n",
        "                vmin=0, vmax=1, square=True)\n",
        "\n",
        "    ax2.set_xlabel('Predicted Label', fontweight='bold')\n",
        "    ax2.set_ylabel('True Label', fontweight='bold')\n",
        "    ax2.set_title('Normalized Confusion Matrix', fontweight='bold', fontsize=13)\n",
        "    ax2.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    st.pyplot(fig)\n",
        "    plt.close()\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"#### Best & Worst Performing Classes\")\n",
        "\n",
        "    col_best, col_worst = st.columns(2)\n",
        "\n",
        "    with col_best:\n",
        "        st.markdown(\"**Top 5 Best Classes (by F1-Score)**\")\n",
        "        top_5_idx = np.argsort(f1_per_class)[-5:][::-1]\n",
        "\n",
        "        for idx in top_5_idx:\n",
        "            st.markdown(f\"\"\"\n",
        "            <div style=\"background: #e8f5e9; padding: 0.5rem;\n",
        "                        border-radius: 8px; margin: 0.3rem 0;\">\n",
        "                <b>{class_names[idx]}</b><br>\n",
        "                F1: {f1_per_class[idx]:.2f}% |\n",
        "                Precision: {precision_per_class[idx]:.2f}% |\n",
        "                Recall: {recall_per_class[idx]:.2f}%\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    with col_worst:\n",
        "        st.markdown(\"**Bottom 5 Classes (by F1-Score)**\")\n",
        "        bottom_5_idx = np.argsort(f1_per_class)[:5]\n",
        "\n",
        "        for idx in bottom_5_idx:\n",
        "            st.markdown(f\"\"\"\n",
        "            <div style=\"background: #fff3e0; padding: 0.5rem;\n",
        "                        border-radius: 8px; margin: 0.3rem 0;\">\n",
        "                <b>{class_names[idx]}</b><br>\n",
        "                F1: {f1_per_class[idx]:.2f}% |\n",
        "                Precision: {precision_per_class[idx]:.2f}% |\n",
        "                Recall: {recall_per_class[idx]:.2f}%\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"### Export Confusion Matrix\")\n",
        "\n",
        "    col_d1, col_d2, col_d3 = st.columns(3)\n",
        "\n",
        "    with col_d1:\n",
        "        buffer = BytesIO()\n",
        "        np.save(buffer, cm)\n",
        "        buffer.seek(0)\n",
        "\n",
        "        st.download_button(\n",
        "            \"Download .npy\",\n",
        "            buffer,\n",
        "            f\"confusion_matrix_{datetime.now().strftime('%Y%m%d_%H%M%S')}.npy\",\n",
        "            \"application/octet-stream\"\n",
        "        )\n",
        "\n",
        "    with col_d2:\n",
        "        cm_df = pd.DataFrame(cm, columns=display_names, index=display_names)\n",
        "        csv_buffer = StringIO()\n",
        "        cm_df.to_csv(csv_buffer)\n",
        "        csv_string = csv_buffer.getvalue()\n",
        "        st.download_button(\n",
        "            \"Download CSV\",\n",
        "            csv_string,\n",
        "            f\"confusion_matrix_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\",\n",
        "            \"text/csv\"\n",
        "        )\n",
        "\n",
        "    with col_d3:\n",
        "        metrics_data = {\n",
        "            'overall_accuracy': float(accuracy),\n",
        "            'macro_precision': float(macro_precision),\n",
        "            'macro_recall': float(macro_recall),\n",
        "            'macro_f1': float(macro_f1),\n",
        "            'per_class_metrics': [\n",
        "                {\n",
        "                    'class': class_names[i],\n",
        "                    'precision': float(precision_per_class[i]),\n",
        "                    'recall': float(recall_per_class[i]),\n",
        "                    'f1_score': float(f1_per_class[i])\n",
        "                } for i in range(num_classes)\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        json_buffer = BytesIO()\n",
        "        json_buffer.write(json.dumps(metrics_data, indent=2).encode())\n",
        "        json_buffer.seek(0)\n",
        "\n",
        "        st.download_button(\n",
        "            \"Download Metrics (JSON)\",\n",
        "            json_buffer,\n",
        "            f\"metrics_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\",\n",
        "            \"application/json\"\n",
        "        )"
      ],
      "id": "1271392ff81c5634",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "796dbc9cda02cf7c"
      },
      "cell_type": "markdown",
      "source": [
        "# Webcam Input Function (FIXED)"
      ],
      "id": "796dbc9cda02cf7c"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-18T15:20:01.105276Z",
          "start_time": "2025-12-18T15:20:01.084869Z"
        },
        "id": "efff8009f228a628"
      },
      "cell_type": "code",
      "source": [
        "def webcam_input():\n",
        "    st.markdown(\"### Live Camera Capture\")\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "    <div class=\"info-box\">\n",
        "    <b>Camera Instructions:</b><br>\n",
        "    1. Click the \"Take a picture\" button below<br>\n",
        "    2. Allow camera access in your browser when prompted<br>\n",
        "    3. Position the plant leaf clearly in the center of frame<br>\n",
        "    4. Ensure good lighting for best results<br>\n",
        "    5. Click the capture button to take the photo\n",
        "    </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    with st.expander(\"Tips for Best Results\"):\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            st.markdown(\"\"\"\n",
        "            **Good Practices:**\n",
        "            - Use natural daylight\n",
        "            - Keep leaf flat and centered\n",
        "            - Fill the frame with the leaf\n",
        "            - Avoid shadows on the leaf\n",
        "            - Hold camera steady\n",
        "            \"\"\")\n",
        "\n",
        "        with col2:\n",
        "            st.markdown(\"\"\"\n",
        "            **Avoid:**\n",
        "            - Blurry or shaky images\n",
        "            - Dark or overexposed photos\n",
        "            - Leaf too small in frame\n",
        "            - Multiple leaves overlapping\n",
        "            - Dirty camera lens\n",
        "            \"\"\")\n",
        "\n",
        "    img_file = st.camera_input(\"Take a picture of the plant leaf\")\n",
        "\n",
        "    if img_file is not None:\n",
        "        img = Image.open(img_file).convert('RGB')\n",
        "\n",
        "        st.success(\"Image captured successfully!\")\n",
        "\n",
        "        col_info1, col_info2, col_info3 = st.columns(3)\n",
        "\n",
        "        with col_info1:\n",
        "            st.metric(\"Resolution\", f\"{img.width}×{img.height}\")\n",
        "        with col_info2:\n",
        "            st.metric(\"File Size\", f\"{img_file.size / 1024:.1f} KB\")\n",
        "        with col_info3:\n",
        "            img_array = np.array(img)\n",
        "            brightness = np.mean(img_array)\n",
        "            quality = \"Good\" if 50 < brightness < 200 else \"Check Lighting\"\n",
        "            st.metric(\"Lighting\", quality)\n",
        "\n",
        "        if st.button(\"Retake Photo\"):\n",
        "            st.rerun()\n",
        "\n",
        "        return img\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def webcam_input_with_preview(models_dict, selected_model, class_data):\n",
        "    st.markdown(\"### Live Camera with Instant Analysis\")\n",
        "\n",
        "    if selected_model not in models_dict or not models_dict[selected_model].get('loaded', False):\n",
        "        st.error(f\"Model {selected_model} not available\")\n",
        "        return None, None\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "    <div class=\"info-box\">\n",
        "    <b>Quick Capture Mode:</b><br>\n",
        "    Take a photo and get instant AI analysis!\n",
        "    </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    col_set1, col_set2 = st.columns(2)\n",
        "\n",
        "    with col_set1:\n",
        "        auto_analyze = st.checkbox(\"Auto-analyze after capture\", value=True,\n",
        "                                   help=\"Automatically run prediction when image is captured\")\n",
        "\n",
        "    with col_set2:\n",
        "        show_confidence_bar = st.checkbox(\"Show confidence bar\", value=True)\n",
        "\n",
        "    img_file = st.camera_input(\"Capture Plant Leaf\")\n",
        "\n",
        "    if img_file is not None:\n",
        "        img = Image.open(img_file).convert('RGB')\n",
        "\n",
        "        col1, col2 = st.columns([1, 1])\n",
        "\n",
        "        with col1:\n",
        "            st.markdown(\"**Captured Image**\")\n",
        "            st.image(img, use_container_width=True)\n",
        "\n",
        "            img_array = np.array(img)\n",
        "            brightness = np.mean(img_array)\n",
        "            contrast = np.std(img_array)\n",
        "\n",
        "            if brightness < 50:\n",
        "                st.warning(\"Image is too dark. Consider better lighting.\")\n",
        "            elif brightness > 200:\n",
        "                st.warning(\"Image is overexposed. Reduce lighting.\")\n",
        "\n",
        "            if contrast < 20:\n",
        "                st.warning(\"Low contrast. Image may be blurry.\")\n",
        "\n",
        "        with col2:\n",
        "            if auto_analyze:\n",
        "                st.markdown(\"**AI Analysis**\")\n",
        "\n",
        "                with st.spinner(\"Analyzing...\"):\n",
        "                    start_time = time.time()\n",
        "\n",
        "                    model = models_dict[selected_model]['model']\n",
        "                    preprocess_fn = models_dict[selected_model]['preprocess']\n",
        "\n",
        "                    top3_classes, top3_probs, gradcam_img, all_preds = predict_disease(\n",
        "                        img, model, class_data, preprocess_fn\n",
        "                    )\n",
        "\n",
        "                    inference_time = time.time() - start_time\n",
        "\n",
        "                if top3_classes:\n",
        "                    prediction = top3_classes[0]\n",
        "                    confidence = top3_probs[0]\n",
        "\n",
        "                    conf_color = \"#4caf50\" if confidence > 80 else \"#ff9800\" if confidence > 60 else \"#f44336\"\n",
        "\n",
        "                    st.markdown(f\"\"\"\n",
        "                    <div style=\"background: white; padding: 1.5rem; border-radius: 15px;\n",
        "                                border-left: 6px solid {conf_color};\n",
        "                                box-shadow: 0 4px 15px rgba(0,0,0,0.1);\">\n",
        "                        <h3 style=\"margin: 0; color: #2e7d32;\">{prediction}</h3>\n",
        "                        <h1 style=\"margin: 0.5rem 0; color: {conf_color}; font-size: 2.5rem;\">\n",
        "                            {confidence:.1f}%\n",
        "                        </h1>\n",
        "                        <p style=\"margin: 0; color: #666; font-size: 0.9rem;\">\n",
        "                            {inference_time:.2f}s | {selected_model}\n",
        "                        </p>\n",
        "                    </div>\n",
        "                    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                    if show_confidence_bar:\n",
        "                        st.markdown(\"**Top 3 Predictions:**\")\n",
        "                        for i in range(3):\n",
        "                            medal = \"1\" if i == 0 else \"2\" if i == 1 else \"3\"\n",
        "                            st.write(f\"{medal}. {top3_classes[i]}\")\n",
        "                            st.progress(top3_probs[i] / 100)\n",
        "                            st.caption(f\"{top3_probs[i]:.1f}%\")\n",
        "\n",
        "                    st.markdown(\"---\")\n",
        "                    col_btn1, col_btn2 = st.columns(2)\n",
        "\n",
        "                    with col_btn1:\n",
        "                        if st.button(\"Retake\", use_container_width=True):\n",
        "                            st.rerun()\n",
        "\n",
        "                    with col_btn2:\n",
        "                        if st.button(\"Save Result\", use_container_width=True):\n",
        "                            st.session_state['last_webcam_result'] = {\n",
        "                                'image': img,\n",
        "                                'prediction': prediction,\n",
        "                                'confidence': confidence,\n",
        "                                'timestamp': datetime.now()\n",
        "                            }\n",
        "                            st.success(\"Result saved!\")\n",
        "\n",
        "                    return img, {\n",
        "                        'top3_classes': top3_classes,\n",
        "                        'top3_probs': top3_probs,\n",
        "                        'gradcam_img': gradcam_img,\n",
        "                        'inference_time': inference_time\n",
        "                    }\n",
        "            else:\n",
        "                st.info(\"Image captured. Click 'Analyze' to run prediction.\")\n",
        "\n",
        "                if st.button(\"Analyze Image\", use_container_width=True):\n",
        "                    st.rerun()\n",
        "\n",
        "        return img, None\n",
        "\n",
        "    return None, None\n",
        "\n",
        "\n",
        "def webcam_continuous_mode(models_dict, selected_model, class_data, fps_limit=2):\n",
        "    st.markdown(\"### Continuous Monitoring Mode\")\n",
        "\n",
        "    st.warning(\"\"\"\n",
        "    Note: Streamlit's camera widget captures single frames, not continuous video.\n",
        "    For true continuous monitoring, consider using a video processing library with\n",
        "    OpenCV or deploy as a separate web application.\n",
        "    \"\"\")\n",
        "\n",
        "    st.info(\"\"\"\n",
        "    Alternative: Use the standard webcam capture and click 'Retake' for new predictions.\n",
        "    For production use, implement a dedicated video streaming service.\n",
        "    \"\"\")"
      ],
      "id": "efff8009f228a628",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "7d63b064cc25a4f6"
      },
      "cell_type": "markdown",
      "source": [
        "# Main App"
      ],
      "id": "7d63b064cc25a4f6"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-18T15:22:30.411620Z",
          "start_time": "2025-12-18T15:22:30.396957Z"
        },
        "id": "618be37fea781ae3"
      },
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    models_dict, class_data, available_models = initialize_app()\n",
        "\n",
        "    if not available_models:\n",
        "        st.error(\"No models available! Please check model paths.\")\n",
        "        st.stop()\n",
        "\n",
        "    st.sidebar.title(\"🌿 Navigation\")\n",
        "    app_mode = st.sidebar.radio(\n",
        "        \"Go to\",\n",
        "        [\"Home\", \"Disease Detection\", \"Model Comparison\", \"Batch Processing\",\n",
        "         \"Real-Time Detection\", \"Performance Metrics\"],\n",
        "        help=\"Choose a feature to explore\"\n",
        "    )\n",
        "\n",
        "    st.sidebar.markdown(\"---\")\n",
        "\n",
        "    selected_model_name = st.sidebar.selectbox(\n",
        "        \"🤖 Select AI Model\",\n",
        "        available_models,\n",
        "        help=\"Choose different architectures to see how they perform\"\n",
        "    )\n",
        "    st.sidebar.markdown(\"---\")\n",
        "    use_tflite = st.sidebar.checkbox(\n",
        "        \"🚀 Use TFLite (Fast Mode)\",\n",
        "        value=False,\n",
        "        help=\"Use optimized TFLite model for faster inference\"\n",
        "    )\n",
        "\n",
        "    if use_tflite:\n",
        "        st.sidebar.success(\"⚡ TFLite Mode: 3x faster!\")\n",
        "        st.sidebar.caption(\"Optimized for mobile/edge devices\")\n",
        "\n",
        "    st.sidebar.markdown(\"---\")\n",
        "    display_model_status()\n",
        "\n",
        "    if app_mode == \"Home\":\n",
        "        st.title(\"🌿 Plant Disease Detection System\")\n",
        "\n",
        "        st.markdown(\"\"\"\n",
        "        <div class=\"success-box\">\n",
        "        <h3>Welcome to the Smart Agriculture Assistant!</h3>\n",
        "        <p>This advanced system uses Deep Learning to identify plant diseases with high accuracy.</p>\n",
        "        </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        st.markdown(\"### 🚀 Key Features\")\n",
        "\n",
        "        col1, col2, col3 = st.columns(3)\n",
        "\n",
        "        with col1:\n",
        "            st.markdown(\"\"\"\n",
        "            **🎯 Accurate Detection**\n",
        "            - 3 state-of-the-art AI models\n",
        "            - 90%+ accuracy rate\n",
        "            - Real-time predictions\n",
        "            \"\"\")\n",
        "\n",
        "        with col2:\n",
        "            st.markdown(\"\"\"\n",
        "            **🔍 Explainable AI**\n",
        "            - Grad-CAM visualizations\n",
        "            - Understand AI decisions\n",
        "            - Confidence scoring\n",
        "            \"\"\")\n",
        "\n",
        "        with col3:\n",
        "            st.markdown(\"\"\"\n",
        "            **⚡ Fast Processing**\n",
        "            - Instant results\n",
        "            - Batch processing\n",
        "            - Video analysis support\n",
        "            \"\"\")\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.markdown(\"### 📖 How to Use\")\n",
        "\n",
        "        st.markdown(\"\"\"\n",
        "        <div class=\"info-box\">\n",
        "        <b>Step-by-step Guide:</b><br><br>\n",
        "        1. <b>Select a Model</b> from the sidebar (ResNet50, EfficientNet, or MobileNet)<br>\n",
        "        2. <b>Choose Detection Mode</b> - Single image, batch, or real-time<br>\n",
        "        3. <b>Upload/Capture Image</b> - Use file upload or camera<br>\n",
        "        4. <b>Get Results</b> - AI analyzes and shows diagnosis with confidence<br>\n",
        "        5. <b>View Explanation</b> - See Grad-CAM heatmap showing AI's focus areas\n",
        "        </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.markdown(\"### 💡 Best Practices\")\n",
        "\n",
        "        col_a, col_b = st.columns(2)\n",
        "\n",
        "        with col_a:\n",
        "            st.markdown(\"\"\"\n",
        "            **✅ Do:**\n",
        "            - Use clear, well-lit images\n",
        "            - Center the leaf in frame\n",
        "            - Ensure leaf fills most of the image\n",
        "            - Use natural lighting when possible\n",
        "            - Keep leaf flat and in focus\n",
        "            \"\"\")\n",
        "\n",
        "        with col_b:\n",
        "            st.markdown(\"\"\"\n",
        "            **❌ Avoid:**\n",
        "            - Blurry or shaky photos\n",
        "            - Dark or overexposed images\n",
        "            - Multiple leaves overlapping\n",
        "            - Extreme angles or distortion\n",
        "            - Dirty or wet lens\n",
        "            \"\"\")\n",
        "\n",
        "    elif app_mode == \"Disease Detection\":\n",
        "        st.title(\"🔬 Disease Diagnosis\")\n",
        "\n",
        "        tab1, tab2 = st.tabs([\"📤 Upload Image\", \"📷 Use Camera\"])\n",
        "\n",
        "        with tab1:\n",
        "            st.markdown(\"### Upload Plant Leaf Image\")\n",
        "\n",
        "            uploaded_file = st.file_uploader(\n",
        "                \"Choose a leaf image...\",\n",
        "                type=[\"jpg\", \"jpeg\", \"png\"],\n",
        "                help=\"Upload a clear image of the affected plant leaf\"\n",
        "            )\n",
        "\n",
        "            if uploaded_file is not None:\n",
        "                image = Image.open(uploaded_file).convert('RGB')\n",
        "\n",
        "                col1, col2 = st.columns([1, 1])\n",
        "\n",
        "                with col1:\n",
        "                    st.markdown(\"**Original Image**\")\n",
        "                    st.image(image, use_container_width=True)\n",
        "\n",
        "                    st.markdown(\"**Image Info:**\")\n",
        "                    st.write(f\"📐 Size: {image.width}×{image.height}\")\n",
        "                    st.write(f\"📦 File: {uploaded_file.size / 1024:.1f} KB\")\n",
        "\n",
        "                with col2:\n",
        "                    st.markdown(\"### 🎨 Image Enhancement\")\n",
        "\n",
        "                    with st.expander(\"Adjustment Controls\", expanded=False):\n",
        "                        params = show_enhancement_controls()\n",
        "\n",
        "                        if any(params[k] != 1.0 for k in ['brightness', 'contrast', 'sharpness', 'color']) or params.get('use_clahe'):\n",
        "                            enhanced_image = apply_enhancements(image, params)\n",
        "                            st.markdown(\"**Enhanced Preview:**\")\n",
        "                            st.image(enhanced_image, use_container_width=True)\n",
        "                            use_enhanced = st.checkbox(\"Use enhanced image for analysis\", value=True)\n",
        "                            final_image = enhanced_image if use_enhanced else image\n",
        "                        else:\n",
        "                            final_image = image\n",
        "\n",
        "                    if not 'params' in locals():\n",
        "                        final_image = image\n",
        "\n",
        "                st.markdown(\"---\")\n",
        "\n",
        "                col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 1])\n",
        "\n",
        "                with col_btn1:\n",
        "                    use_ensemble = st.checkbox(\"🔄 Use enhancement ensemble\", value=False,\n",
        "                                              help=\"Average predictions from original + enhanced\")\n",
        "\n",
        "                with col_btn2:\n",
        "                    show_gradcam = st.checkbox(\"🔥 Show Grad-CAM\", value=True,\n",
        "                                              help=\"Visualize what AI focuses on\")\n",
        "\n",
        "                with col_btn3:\n",
        "                    export_results_btn = st.checkbox(\"💾 Export results\", value=False)\n",
        "\n",
        "                if st.button(\"🔍 Analyze Leaf\", use_container_width=True, type=\"primary\"):\n",
        "                    with st.spinner(f\"🤖 AI analyzing using {selected_model_name}...\"):\n",
        "                        result = predict_with_model(\n",
        "                            final_image,\n",
        "                            selected_model_name,\n",
        "                            models_dict,\n",
        "                            class_data,\n",
        "                            use_enhancement=use_ensemble\n",
        "                        )\n",
        "\n",
        "                    if result:\n",
        "                        st.markdown(\"---\")\n",
        "                        st.markdown(\"### 📊 Diagnosis Results\")\n",
        "\n",
        "                        prediction = result['top3_classes'][0]\n",
        "                        confidence = result['top3_probs'][0]\n",
        "\n",
        "                        conf_color = \"#4caf50\" if confidence > 80 else \"#ff9800\" if confidence > 60 else \"#f44336\"\n",
        "\n",
        "                        st.markdown(f\"\"\"\n",
        "                        <div class=\"prediction-card\">\n",
        "                            <h2 style=\"margin:0; color: #2e7d32;\">🌱 Diagnosis: {prediction}</h2>\n",
        "                            <h1 style=\"margin:0.5rem 0; color:{conf_color}; font-size:3rem;\">\n",
        "                                {confidence:.2f}%\n",
        "                            </h1>\n",
        "                            <p style=\"margin:0; color:#666;\">\n",
        "                                ⏱️ Processed in {result['inference_time']:.3f}s using {selected_model_name}\n",
        "                            </p>\n",
        "                        </div>\n",
        "                        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                        col_r1, col_r2, col_r3 = st.columns(3)\n",
        "\n",
        "                        with col_r1:\n",
        "                            st.metric(\"Top Prediction\", prediction[:20])\n",
        "                        with col_r2:\n",
        "                            st.metric(\"Confidence\", f\"{confidence:.1f}%\")\n",
        "                        with col_r3:\n",
        "                            st.metric(\"Model\", selected_model_name)\n",
        "\n",
        "                        st.markdown(\"---\")\n",
        "                        st.markdown(\"#### 📈 Top 3 Predictions\")\n",
        "\n",
        "                        for i in range(min(3, len(result['top3_classes']))):\n",
        "                            with st.container():\n",
        "                                col_p1, col_p2 = st.columns([3, 1])\n",
        "                                with col_p1:\n",
        "                                    st.write(f\"**{i+1}. {result['top3_classes'][i]}**\")\n",
        "                                with col_p2:\n",
        "                                    st.write(f\"**{result['top3_probs'][i]:.2f}%**\")\n",
        "                                st.progress(result['top3_probs'][i] / 100)\n",
        "\n",
        "                        if show_gradcam and result.get('heatmap') is not None:\n",
        "                            st.markdown(\"---\")\n",
        "                            display_gradcam_analysis(\n",
        "                                final_image,\n",
        "                                result['heatmap'],\n",
        "                                prediction,\n",
        "                                confidence\n",
        "                            )\n",
        "\n",
        "                        if export_results_btn:\n",
        "                            st.markdown(\"---\")\n",
        "                            st.markdown(\"### 💾 Export Results\")\n",
        "\n",
        "                            zip_package = export_results_package(final_image, result, class_data)\n",
        "\n",
        "                            if zip_package:\n",
        "                                st.download_button(\n",
        "                                    \"📦 Download Complete Results Package\",\n",
        "                                    zip_package,\n",
        "                                    f\"plant_disease_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip\",\n",
        "                                    \"application/zip\",\n",
        "                                    use_container_width=True\n",
        "                                )\n",
        "\n",
        "        with tab2:\n",
        "            st.markdown(\"### 📷 Live Camera Capture\")\n",
        "            img, cam_result = webcam_input_with_preview(models_dict, selected_model_name, class_data)\n",
        "\n",
        "    elif app_mode == \"Model Comparison\":\n",
        "        st.title(\"🔬 Multi-Model Comparison\")\n",
        "\n",
        "        st.markdown(\"\"\"\n",
        "        <div class=\"info-box\">\n",
        "        Compare predictions from all available models simultaneously to increase confidence in diagnosis.\n",
        "        </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        uploaded_file = st.file_uploader(\"Upload leaf image for comparison\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "        if uploaded_file is not None:\n",
        "            image = Image.open(uploaded_file).convert('RGB')\n",
        "\n",
        "            col1, col2 = st.columns([1, 2])\n",
        "\n",
        "            with col1:\n",
        "                st.markdown(\"**Test Image**\")\n",
        "                st.image(image, use_container_width=True)\n",
        "\n",
        "            with col2:\n",
        "                st.markdown(\"**Comparison Settings**\")\n",
        "                use_enhancement = st.checkbox(\"Use enhancement ensemble\", value=False)\n",
        "                show_all_gradcams = st.checkbox(\"Show all Grad-CAMs\", value=True)\n",
        "\n",
        "            if st.button(\"🚀 Run Multi-Model Analysis\", use_container_width=True, type=\"primary\"):\n",
        "                results = compare_model_predictions(image, models_dict, class_data, use_enhancement)\n",
        "\n",
        "                if results:\n",
        "                    display_comparison_results(results, class_data)\n",
        "\n",
        "                    if show_all_gradcams:\n",
        "                        st.markdown(\"---\")\n",
        "                        st.markdown(\"### 🔥 Grad-CAM Comparison\")\n",
        "\n",
        "                        cols = st.columns(len(results))\n",
        "\n",
        "                        for idx, (model_name, result) in enumerate(results.items()):\n",
        "                            with cols[idx]:\n",
        "                                st.markdown(f\"**{model_name}**\")\n",
        "\n",
        "                                if result.get('heatmap') is not None:\n",
        "                                    img_array = np.array(image.resize(IMG_SIZE))\n",
        "                                    _, _, overlay = create_gradcam_visualization(img_array, result['heatmap'])\n",
        "                                    st.image(overlay, use_container_width=True)\n",
        "                                else:\n",
        "                                    st.info(\"Grad-CAM not available\")\n",
        "\n",
        "                    grid_img = create_comparison_grid(image, results, class_data)\n",
        "\n",
        "                    st.markdown(\"---\")\n",
        "                    st.markdown(\"### 📸 Comparison Grid\")\n",
        "                    st.image(grid_img, use_container_width=True)\n",
        "\n",
        "    elif app_mode == \"Batch Processing\":\n",
        "        st.title(\"📦 Batch Image Processing\")\n",
        "\n",
        "        st.markdown(\"\"\"\n",
        "        <div class=\"info-box\">\n",
        "        Upload multiple images at once for efficient bulk processing. Perfect for analyzing entire crops.\n",
        "        </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        uploaded_files = st.file_uploader(\n",
        "            \"Upload multiple leaf images\",\n",
        "            type=[\"jpg\", \"jpeg\", \"png\"],\n",
        "            accept_multiple_files=True\n",
        "        )\n",
        "\n",
        "        if uploaded_files:\n",
        "            st.success(f\"📁 {len(uploaded_files)} files uploaded\")\n",
        "\n",
        "            col_opt1, col_opt2 = st.columns(2)\n",
        "\n",
        "            with col_opt1:\n",
        "                use_enhancement = st.checkbox(\"Use enhancement ensemble\", value=False)\n",
        "\n",
        "            with col_opt2:\n",
        "                save_viz = st.checkbox(\"Save visualizations\", value=False)\n",
        "\n",
        "            if st.button(\"🚀 Process All Images\", use_container_width=True, type=\"primary\"):\n",
        "                results, visualizations = batch_process_images(\n",
        "                    uploaded_files,\n",
        "                    models_dict,\n",
        "                    selected_model_name,\n",
        "                    class_data,\n",
        "                    use_enhancement=use_enhancement,\n",
        "                    save_visualizations=save_viz\n",
        "                )\n",
        "\n",
        "                if results:\n",
        "                    display_batch_results(results, visualizations)\n",
        "\n",
        "                    st.markdown(\"---\")\n",
        "                    st.markdown(\"### 💾 Export Batch Results\")\n",
        "\n",
        "                    col_e1, col_e2, col_e3 = st.columns(3)\n",
        "\n",
        "                    with col_e1:\n",
        "                        csv_buffer = export_batch_results(results, format='csv')\n",
        "                        if csv_buffer:\n",
        "                            st.download_button(\n",
        "                                \"📄 Download CSV\",\n",
        "                                csv_buffer,\n",
        "                                f\"batch_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\",\n",
        "                                \"text/csv\",\n",
        "                                use_container_width=True\n",
        "                            )\n",
        "\n",
        "                    with col_e2:\n",
        "                        json_buffer = export_batch_results(results, format='json')\n",
        "                        if json_buffer:\n",
        "                            st.download_button(\n",
        "                                \"📋 Download JSON\",\n",
        "                                json_buffer,\n",
        "                                f\"batch_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\",\n",
        "                                \"application/json\",\n",
        "                                use_container_width=True\n",
        "                            )\n",
        "\n",
        "                    with col_e3:\n",
        "                        excel_buffer = export_batch_results(results, format='excel')\n",
        "                        if excel_buffer:\n",
        "                            st.download_button(\n",
        "                                \"📊 Download Excel\",\n",
        "                                excel_buffer,\n",
        "                                f\"batch_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\",\n",
        "                                \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\",\n",
        "                                use_container_width=True\n",
        "                            )\n",
        "\n",
        "    elif app_mode == \"Real-Time Detection\":\n",
        "        st.title(\"📹 Real-Time Detection\")\n",
        "\n",
        "        tab1, tab2 = st.tabs([\"📷 Live Camera\", \"🎥 Video Upload\"])\n",
        "\n",
        "        with tab1:\n",
        "            webcam_realtime_detection(\n",
        "                models_dict,\n",
        "                selected_model_name,\n",
        "                class_data,\n",
        "                confidence_threshold=60.0,\n",
        "                show_fps=True\n",
        "            )\n",
        "\n",
        "        with tab2:\n",
        "            st.markdown(\"### 🎥 Video File Analysis\")\n",
        "\n",
        "            uploaded_video = st.file_uploader(\"Upload video file\", type=['mp4', 'avi', 'mov'])\n",
        "\n",
        "            if uploaded_video:\n",
        "                col_v1, col_v2 = st.columns(2)\n",
        "\n",
        "                with col_v1:\n",
        "                    process_every_n = st.slider(\"Process every N frames\", 1, 30, 5)\n",
        "\n",
        "                with col_v2:\n",
        "                    max_frames = st.slider(\"Max frames to process\", 10, 500, 100)\n",
        "\n",
        "                if st.button(\"🎬 Process Video\", use_container_width=True, type=\"primary\"):\n",
        "                    video_results = video_file_processing(\n",
        "                        uploaded_video,\n",
        "                        models_dict,\n",
        "                        selected_model_name,\n",
        "                        class_data,\n",
        "                        process_every_n_frames=process_every_n,\n",
        "                        max_frames=max_frames\n",
        "                    )\n",
        "\n",
        "                    if video_results:\n",
        "                        display_video_results(video_results)\n",
        "\n",
        "    elif app_mode == \"Performance Metrics\":\n",
        "        st.title(\"📊 Model Performance Analysis\")\n",
        "\n",
        "        st.markdown(\"\"\"\n",
        "        <div class=\"info-box\">\n",
        "        View detailed performance metrics including confusion matrices and per-class statistics.\n",
        "        </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        if class_data:\n",
        "            if 'formatted_names' in class_data:\n",
        "                class_names = class_data['formatted_names']\n",
        "            elif isinstance(class_data, dict) and '0' in class_data:\n",
        "                class_names = [class_data[str(i)]['name'] for i in range(len(class_data))]\n",
        "            elif isinstance(class_data, list):\n",
        "                class_names = class_data\n",
        "            else:\n",
        "                class_names = None\n",
        "        else:\n",
        "            class_names = None\n",
        "\n",
        "        show_confusion_matrix(actual_cm=None, class_names=class_names)\n",
        "\n",
        "    st.sidebar.markdown(\"---\")\n",
        "    st.sidebar.markdown(\"### ℹ️ About\")\n",
        "    st.sidebar.info(\"\"\"\n",
        "    **Plant Disease Detection v1.0**\n",
        "\n",
        "    AI-powered agricultural disease diagnosis system using deep learning.\n",
        "\n",
        "    **Models:**\n",
        "    - ResNet50\n",
        "    - EfficientNetB3\n",
        "    - MobileNet\n",
        "\n",
        "    **Team:** AI Skills Course\n",
        "    **Date:** December 2024\n",
        "    \"\"\")\n",
        "\n"
      ],
      "id": "618be37fea781ae3",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-18T15:22:31.735707Z",
          "start_time": "2025-12-18T15:22:31.491488Z"
        },
        "id": "346f5a3743fc0f2f"
      },
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "id": "346f5a3743fc0f2f",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "a35b626535cbfff2"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [],
      "id": "a35b626535cbfff2"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}